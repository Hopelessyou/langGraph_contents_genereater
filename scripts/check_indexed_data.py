#!/usr/bin/env python3
"""ì¸ë±ì‹±ëœ ë°ì´í„° í™•ì¸ ìŠ¤í¬ë¦½íŠ¸"""

import sys
from pathlib import Path
import asyncio

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

from src.rag import DocumentIndexer, VectorStore, EmbeddingGenerator
from src.rag.incremental_updater import IncrementalUpdater
from src.rag.monitor import IndexMonitor


async def check_indexed_data():
    """ì¸ë±ì‹±ëœ ë°ì´í„° ì¢…í•© í™•ì¸"""
    
    print("=" * 60)
    print("ğŸ“Š ì¸ë±ì‹± ë°ì´í„° í™•ì¸")
    print("=" * 60)
    
    # 1. ë²¡í„° DB ìƒíƒœ í™•ì¸
    print("\n1ï¸âƒ£ ë²¡í„° DB ìƒíƒœ")
    print("-" * 60)
    try:
        vector_store = VectorStore()
        count = await vector_store.get_count()
        print(f"   ë²¡í„° DB ì²­í¬ ìˆ˜: {count}ê°œ")
        print(f"   ì»¬ë ‰ì…˜ ì´ë¦„: {vector_store.collection_name}")
        
        if count == 0:
            print("\nâš ï¸  ë²¡í„° DBê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
            print("   ë°ì´í„°ë¥¼ ì¸ë±ì‹±í•˜ì„¸ìš”:")
            print("   python scripts/process_and_index.py --input-dir data/processed/cases --doc-type case")
            return
    except Exception as e:
        print(f"   âŒ ë²¡í„° DB í™•ì¸ ì‹¤íŒ¨: {e}")
        return
    
    # 2. ì¸ë±ì‹± ìƒíƒœ í™•ì¸
    print("\n2ï¸âƒ£ ì¸ë±ì‹± ìƒíƒœ")
    print("-" * 60)
    try:
        indexer = DocumentIndexer()
        updater = IncrementalUpdater(indexer)
        monitor = IndexMonitor(indexer.vector_store, updater)
        
        status = updater.get_status()
        health = monitor.get_health_status()
        
        print(f"   ì¸ë±ì‹±ëœ ë¬¸ì„œ ìˆ˜: {status['indexed_count']}ê°œ")
        print(f"   ë²¡í„° DB ì²­í¬ ìˆ˜: {health['vector_db_count']}ê°œ")
        print(f"   ìƒíƒœ: {health['status']}")
        
        # í†µê³„
        statistics = monitor.get_statistics()
        if statistics.get('average_chunks_per_document'):
            print(f"   ë¬¸ì„œë‹¹ í‰ê·  ì²­í¬ ìˆ˜: {statistics['average_chunks_per_document']:.1f}ê°œ")
    except Exception as e:
        print(f"   âš ï¸  ì¸ë±ì‹± ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # 3. ì¼ê´€ì„± í™•ì¸
    print("\n3ï¸âƒ£ ì¼ê´€ì„± í™•ì¸")
    print("-" * 60)
    try:
        consistency = monitor.check_consistency()
        if consistency['consistent']:
            print("   âœ… ì¸ë±ìŠ¤ ì¼ê´€ì„±: ì •ìƒ")
        else:
            print("   âŒ ì¸ë±ìŠ¤ ì¼ê´€ì„±: ë¬¸ì œ ë°œê²¬")
            for issue in consistency.get('issues', []):
                print(f"      - {issue}")
    except Exception as e:
        print(f"   âš ï¸  ì¼ê´€ì„± í™•ì¸ ì‹¤íŒ¨: {e}")
    
    # 4. ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
    print("\n4ï¸âƒ£ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸")
    print("-" * 60)
    try:
        embedding_gen = EmbeddingGenerator()
        test_query = "ì‚¬ê¸° ë²”ì£„"
        
        print(f"   í…ŒìŠ¤íŠ¸ ì¿¼ë¦¬: '{test_query}'")
        query_embedding = await embedding_gen.embed_text(test_query)
        results = await vector_store.search(
            query_embedding=query_embedding,
            n_results=3
        )
        
        if results.get('ids') and len(results['ids'][0]) > 0:
            print(f"   âœ… ê²€ìƒ‰ ì„±ê³µ: {len(results['ids'][0])}ê°œ ê²°ê³¼")
            print("\n   ê²€ìƒ‰ ê²°ê³¼:")
            for i, doc_id in enumerate(results['ids'][0][:3], 1):
                print(f"   {i}. {doc_id}")
                if results.get('metadatas') and results['metadatas'][0]:
                    metadata = results['metadatas'][0][i-1]
                    print(f"      ì œëª©: {metadata.get('title', 'N/A')}")
                    print(f"      íƒ€ì…: {metadata.get('type', 'N/A')}")
        else:
            print(f"   âŒ ê²€ìƒ‰ ì‹¤íŒ¨: ê²°ê³¼ ì—†ìŒ")
    except Exception as e:
        print(f"   âš ï¸  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
    
    # 5. ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„
    print("\n5ï¸âƒ£ ë¬¸ì„œ íƒ€ì…ë³„ í†µê³„")
    print("-" * 60)
    try:
        import chromadb
        from chromadb.config import Settings
        
        client = chromadb.PersistentClient(
            path=str(Path("./data/vector_db")),
            settings=Settings(anonymized_telemetry=False)
        )
        collection = client.get_collection(vector_store.collection_name)
        
        # ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ë©”íƒ€ë°ì´í„°ë§Œ)
        sample_data = collection.get(limit=100)
        
        if sample_data.get('metadatas'):
            type_counts = {}
            for metadata in sample_data['metadatas']:
                doc_type = metadata.get('type', 'unknown')
                type_counts[doc_type] = type_counts.get(doc_type, 0) + 1
            
            if type_counts:
                for doc_type, count in sorted(type_counts.items()):
                    print(f"   {doc_type}: {count}ê°œ ì²­í¬ (ìƒ˜í”Œ)")
            else:
                print("   í†µê³„ ìˆ˜ì§‘ ë¶ˆê°€")
    except Exception as e:
        print(f"   âš ï¸  í†µê³„ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
    
    print("\n" + "=" * 60)
    print("âœ… í™•ì¸ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(check_indexed_data())

