"""í˜•ë²• PDFë¥¼ ì¡°ë¬¸ë³„ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)


class StatutePDFParser:
    """í˜•ë²• PDF íŒŒì„œ"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def parse_pdf_text(self, pdf_path: Path) -> str:
        """
        PDF íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PDF í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        try:
            import PyPDF2
        except ImportError:
            logger.error("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install PyPDF2'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            raise
        
        text = ""
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        
        return text
    
    def extract_law_name(self, text: str, pdf_path: Path = None) -> str:
        """
        ë²•ë¥ ëª… ì¶”ì¶œ (íŒŒì¼ëª… ìš°ì„ , í…ìŠ¤íŠ¸ ë‚´ìš© ë³´ì¡°)
        
        Args:
            text: PDF í…ìŠ¤íŠ¸ ë‚´ìš©
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (ì„ íƒ)
            
        Returns:
            ë²•ë¥ ëª…
        """
        # 1. íŒŒì¼ëª…ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ ì‹œë„
        if pdf_path:
            filename = pdf_path.stem  # í™•ì¥ì ì œê±°
            # ì˜ˆ: "í˜•ë²•(ë²•ë¥ )(ì œ20908í˜¸)(20250408)" -> "í˜•ë²•"
            # ì˜ˆ: "íŠ¹ì •ê²½ì œë²”ì£„ ê°€ì¤‘ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥ (ë²•ë¥ )(ì œ15256í˜¸)(20180320)" -> "íŠ¹ì •ê²½ì œë²”ì£„ ê°€ì¤‘ì²˜ë²Œ ë“±ì— ê´€í•œ ë²•ë¥ "
            
            # "(ë²•ë¥ )" ì´ì „ ë¶€ë¶„ ì¶”ì¶œ
            match = re.match(r'^(.+?)(?:\(ë²•ë¥ \)|\(ì œ\d+í˜¸\))', filename)
            if match:
                law_name = match.group(1).strip()
                if law_name:
                    logger.info(f"íŒŒì¼ëª…ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ: {law_name}")
                    return law_name
        
        # 2. PDF í…ìŠ¤íŠ¸ ì²« ë¶€ë¶„ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ ì‹œë„
        # ì¼ë°˜ì ì¸ ë²•ë¥ ëª… íŒ¨í„´
        common_patterns = [
            r"í˜•ë²•",
            r"í˜•ì‚¬ì†Œì†¡ë²•",
            r"ë¯¼ë²•",
            r"ë¯¼ì‚¬ì†Œì†¡ë²•",
            r"íŠ¹ì •ê²½ì œë²”ì£„\s*ê°€ì¤‘ì²˜ë²Œ",
            r"íŠ¹ì •ë²”ì£„\s*ê°€ì¤‘ì²˜ë²Œ",
        ]
        
        for pattern in common_patterns:
            match = re.search(pattern, text[:1000])
            if match:
                law_name = match.group(0).strip()
                logger.info(f"í…ìŠ¤íŠ¸ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ: {law_name}")
                return law_name
        
        # 3. í…ìŠ¤íŠ¸ ì²« ì¤„ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ ì‹œë„
        first_lines = text[:500].split('\n')
        for line in first_lines[:5]:
            line = line.strip()
            if line and len(line) > 2 and len(line) < 100:
                # "ë²•ë¥ " ë˜ëŠ” "ë²•"ìœ¼ë¡œ ëë‚˜ëŠ” ê²½ìš°
                if line.endswith("ë²•") or line.endswith("ë²•ë¥ "):
                    logger.info(f"ì²« ì¤„ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ: {line}")
                    return line
        
        # ê¸°ë³¸ê°’
        logger.warning("ë²•ë¥ ëª…ì„ ì¶”ì¶œí•  ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ 'í˜•ë²•'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return "í˜•ë²•"
    
    def extract_articles(self, text: str, law_name: str = None) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì¡°ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
            law_name: ë²•ë¥ ëª… (í•„í„°ë§ì— ì‚¬ìš©)
            
        Returns:
            ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸ (ì¤‘ë³µ ì œê±°ë¨)
        """
        articles = []
        seen_numbers = set()  # ì¤‘ë³µ ì¡°ë¬¸ ë²ˆí˜¸ ì¶”ì 
        
        # ì¡°ë¬¸ íŒ¨í„´: "ì œXì¡°" ë˜ëŠ” "ì œXì¡°(ì œëª©)"
        # ì˜ˆ: "ì œ1ì¡°(ë²”ì£„ì˜ ì„±ë¦½ê³¼ ì²˜ë²Œ)", "ì œ347ì¡°(ì‚¬ê¸°)"
        article_pattern = r'ì œ(\d+)ì¡°(?:\(([^)]+)\))?'
        
        # finditerë¥¼ ì‚¬ìš©í•˜ì—¬ ë” ì•ˆì •ì ìœ¼ë¡œ ì¡°ë¬¸ ì¶”ì¶œ
        matches = list(re.finditer(article_pattern, text))
        
        if not matches:
            logger.warning("ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return articles
        
        # ì‹¤ì œ ì¡°ë¬¸ì¸ì§€ ì°¸ì¡°ì¸ì§€ íŒë‹¨í•˜ëŠ” í•¨ìˆ˜
        def is_actual_article(match_idx: int) -> bool:
            """ì¡°ë¬¸ì´ ì‹¤ì œ ì¡°ë¬¸ì¸ì§€ ë‹¤ë¥¸ ë²•ë¥  ì°¸ì¡°ì¸ì§€ íŒë‹¨"""
            match = matches[match_idx]
            start_pos = match.start()
            article_num = int(match.group(1))
            article_title = match.group(2) if match.group(2) else None
            
            # ì¡°ë¬¸ ë²ˆí˜¸ê°€ 1-50 ì‚¬ì´ë©´ ê±°ì˜ í™•ì‹¤íˆ ì‹¤ì œ ì¡°ë¬¸ (ë²”ìœ„ í™•ëŒ€)
            if 1 <= article_num <= 50:
                # ë‹¤ë§Œ ë‹¤ë¥¸ ë²•ë¥  ì°¸ì¡° íŒ¨í„´ì´ ë°”ë¡œ ì•ì— ìˆìœ¼ë©´ ì œì™¸
                context_before = text[max(0, start_pos - 80):start_pos]
                other_law_patterns = [
                    r'ã€Œ[^ã€]+ã€\s*ì œ\d+ì¡°',  # ã€Œí˜•ë²•ã€ì œ347ì¡°
                    r'\[[^\]]+\]\s*ì œ\d+ì¡°',  # [í˜•ë²•]ì œ347ì¡°
                    r'ë²•\s*ì œ\d+ì¡°',  # í˜•ë²• ì œ347ì¡° (ë²•ë¥ ëª… ë’¤ì— ë°”ë¡œ ì¡°ë¬¸)
                ]
                for pattern in other_law_patterns:
                    if re.search(pattern, context_before):
                        logger.debug(f"ì œ{article_num}ì¡°: ë‹¤ë¥¸ ë²•ë¥  ì°¸ì¡° íŒ¨í„´ ë°œê²¬ (ì»¨í…ìŠ¤íŠ¸: {context_before[-30:]})")
                        return False
                return True
            
            # ì¡°ë¬¸ ë²ˆí˜¸ê°€ í° ê²½ìš° (50 ì´ˆê³¼) ë” ì‹ ì¤‘í•˜ê²Œ í™•ì¸
            if article_num > 50:
                context_before = text[max(0, start_pos - 150):start_pos]
                context_after = text[start_pos:min(len(text), start_pos + 150)]
                
                # ë‹¤ë¥¸ ë²•ë¥ ëª…ì´ ë°”ë¡œ ì•ì— ìˆëŠ” ê²½ìš° í•„í„°ë§
                other_law_patterns = [
                    r'ã€Œ[^ã€]+ã€\s*ì œ\d+ì¡°',  # ã€Œí˜•ë²•ã€ì œ347ì¡°
                    r'\[[^\]]+\]\s*ì œ\d+ì¡°',  # [í˜•ë²•]ì œ347ì¡°
                    r'ë²•\s*ì œ\d+ì¡°',  # í˜•ë²• ì œ347ì¡°
                ]
                
                for pattern in other_law_patterns:
                    if re.search(pattern, context_before + context_after):
                        logger.debug(f"ì œ{article_num}ì¡°: ë‹¤ë¥¸ ë²•ë¥  ì°¸ì¡°ë¡œ íŒë‹¨")
                        return False
                
                # ì¤„ ì‹œì‘ ë¶€ë¶„ í™•ì¸
                line_start = text[max(0, start_pos - 300):start_pos].rfind('\n')
                line_text = text[line_start + 1:start_pos + 100] if line_start >= 0 else text[:start_pos + 100]
                
                # ì¤„ ì‹œì‘ ë¶€ë¶„ì— "ì œXì¡°"ê°€ ìˆê³  ì œëª©ì´ ìˆìœ¼ë©´ ì‹¤ì œ ì¡°ë¬¸
                if re.match(r'^\s*ì œ\d+ì¡°\(', line_text):
                    logger.debug(f"ì œ{article_num}ì¡°: ì¤„ ì‹œì‘ì— ì œëª©ì´ ìˆì–´ ì‹¤ì œ ì¡°ë¬¸ìœ¼ë¡œ íŒë‹¨")
                    return True
                
                # ì¤„ ì‹œì‘ ë¶€ë¶„ì— "ì œXì¡°"ê°€ ìˆê³ , ê·¸ ë’¤ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆìœ¼ë©´ ì‹¤ì œ ì¡°ë¬¸
                # (ì œëª©ì´ ì—†ì–´ë„ ì‹¤ì œ ì¡°ë¬¸ì¼ ìˆ˜ ìˆìŒ)
                if re.match(r'^\s*ì œ\d+ì¡°', line_text):
                    # ë‹¤ìŒ 100ì ë‚´ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆëŠ”ì§€ í™•ì¸
                    after_match = text[start_pos:min(len(text), start_pos + 200)]
                    # ìˆ«ì, í•œê¸€, íŠ¹ìˆ˜ë¬¸ìê°€ ì„ì—¬ ìˆìœ¼ë©´ ì‹¤ì œ ë‚´ìš©ìœ¼ë¡œ íŒë‹¨
                    if re.search(r'[ê°€-í£]{3,}|[â‘ â‘¡â‘¢â‘£â‘¤]|â‘ |â‘¡|â‘¢', after_match):
                        logger.debug(f"ì œ{article_num}ì¡°: ì¤„ ì‹œì‘ì— ìˆê³  ë‚´ìš©ì´ ìˆì–´ ì‹¤ì œ ì¡°ë¬¸ìœ¼ë¡œ íŒë‹¨")
                        return True
                
                # ê·¸ ì™¸ì—ëŠ” ì°¸ì¡°ì¼ ê°€ëŠ¥ì„±ì´ ë†’ì§€ë§Œ, ë„ˆë¬´ ì—„ê²©í•˜ê²Œ í•„í„°ë§í•˜ì§€ ì•ŠìŒ
                # ì¡°ë¬¸ ë²ˆí˜¸ê°€ 100 ì´í•˜ì´ê³  ì œëª©ì´ ìˆìœ¼ë©´ ì‹¤ì œ ì¡°ë¬¸ìœ¼ë¡œ ê°„ì£¼
                if article_num <= 100 and article_title:
                    logger.debug(f"ì œ{article_num}ì¡°: ì œëª©ì´ ìˆì–´ ì‹¤ì œ ì¡°ë¬¸ìœ¼ë¡œ íŒë‹¨")
                    return True
                
                logger.debug(f"ì œ{article_num}ì¡°: ì°¸ì¡°ë¡œ íŒë‹¨ (ì¡°ë¬¸ ë²ˆí˜¸ê°€ í¬ê³  ì œëª©/ë‚´ìš©ì´ ë¶ˆëª…í™•)")
                    return False
            
            return True
        
        # ì‹¤ì œ ì¡°ë¬¸ë§Œ í•„í„°ë§
        actual_matches = []
        filtered_out = []
        for i, match in enumerate(matches):
            article_num = match.group(1)
            if is_actual_article(i):
                actual_matches.append((i, match))
            else:
                filtered_out.append(article_num)
        
        logger.info(f"ì „ì²´ ì¡°ë¬¸ ë§¤ì¹˜ ìˆ˜: {len(matches)}, ì‹¤ì œ ì¡°ë¬¸ ìˆ˜: {len(actual_matches)}")
        if filtered_out:
            logger.debug(f"í•„í„°ë§ëœ ì¡°ë¬¸ ë²ˆí˜¸: {', '.join(filtered_out[:10])}{'...' if len(filtered_out) > 10 else ''}")
        
        if not actual_matches:
            logger.warning("ì‹¤ì œ ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return articles
        
        # ê° ì‹¤ì œ ì¡°ë¬¸ê³¼ ê·¸ ë‹¤ìŒ ì¡°ë¬¸ ì‚¬ì´ì˜ ë‚´ìš© ì¶”ì¶œ
        for idx, (i, match) in enumerate(actual_matches):
            article_num = match.group(1)
            article_title = match.group(2) if match.group(2) else None
            match_end = match.end()
            
            # ì¤‘ë³µ ì¡°ë¬¸ ë²ˆí˜¸ ì²´í¬
            if article_num in seen_numbers:
                logger.warning(f"ì¤‘ë³µ ì¡°ë¬¸ ë²ˆí˜¸ ê±´ë„ˆë›°ê¸°: ì œ{article_num}ì¡° (ì´ë¯¸ ì¶”ì¶œë¨)")
                continue
            
            # ë‹¤ìŒ ì‹¤ì œ ì¡°ë¬¸ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
            if idx + 1 < len(actual_matches):
                next_idx, next_match = actual_matches[idx + 1]
                end_pos = next_match.start()
            else:
                # ë§ˆì§€ë§‰ ì¡°ë¬¸ì¸ ê²½ìš° í…ìŠ¤íŠ¸ ëê¹Œì§€
                end_pos = len(text)
            
            # ì¡°ë¬¸ ë‚´ìš© ì¶”ì¶œ
            content = text[match_end:end_pos].strip()
            
            # ë‚´ìš© ì •ì œ: ë¶ˆí•„ìš”í•œ ì•ë¶€ë¶„ ì œê±°
            # ì¤„ë°”ê¿ˆ í›„ ì‹œì‘í•˜ëŠ” ê²½ìš° ì²« ì¤„ì˜ ë¶ˆí•„ìš”í•œ ë¶€ë¶„ ì œê±°
            lines = content.split('\n')
            if len(lines) > 1:
                # ì²« ì¤„ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¶ˆì™„ì „í•˜ë©´ ì œê±°
                first_line = lines[0].strip()
                if len(first_line) < 5 or re.match(r'^[ì˜,)\s\d]+$', first_line):
                    content = '\n'.join(lines[1:]).strip()
            
            # "ì œXì¡°"ë¡œ ì‹œì‘í•˜ëŠ” ë¶€ë¶„ ì œê±° (ë‹¤ìŒ ì¡°ë¬¸ì´ í¬í•¨ëœ ê²½ìš°)
            # í•˜ì§€ë§Œ í˜„ì¬ ì¡°ë¬¸ ë²ˆí˜¸ì™€ ë‹¤ë¥¸ ì¡°ë¬¸ë§Œ ì œê±°
            next_article_match = re.search(r'ì œ(\d+)ì¡°', content)
            if next_article_match:
                next_article_num = next_article_match.group(1)
                # ë‹¤ìŒ ì¡°ë¬¸ ë²ˆí˜¸ê°€ í˜„ì¬ ì¡°ë¬¸ ë²ˆí˜¸ë³´ë‹¤ í¬ë©´ (ì‹¤ì œ ë‹¤ìŒ ì¡°ë¬¸)
                if int(next_article_num) > int(article_num):
                content = content[:next_article_match.start()].strip()
            
            # ë‚´ìš© ì •ì œ: ë¶ˆí•„ìš”í•œ ì ‘ë‘ì‚¬ ì œê±°
            # "ì˜2", "ì˜ 2", "), " ê°™ì€ ë¶ˆì™„ì „í•œ ì‹œì‘ ë¶€ë¶„ ì œê±°
            content = re.sub(r'^[ì˜,)\s]+', '', content)
            content = re.sub(r'^ì˜\s*\d+', '', content)
            content = content.strip()
            
            # ë‚´ìš©ì´ ë„ˆë¬´ ì§§ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ê±´ë„ˆë›°ê¸° (ê¸°ì¤€ ì™„í™”: 5ì ì´ìƒ)
            if len(content) < 5:
                logger.warning(f"ë‚´ìš©ì´ ë„ˆë¬´ ì§§ì•„ ê±´ë„ˆë›°ê¸°: ì œ{article_num}ì¡° (ê¸¸ì´: {len(content)}, ë‚´ìš©: {content[:50]})")
                continue
            
            # ë‚´ìš©ì´ ë‹¨ìˆœíˆ ìˆ«ìë‚˜ íŠ¹ìˆ˜ë¬¸ìë§Œ ìˆëŠ” ê²½ìš° í•„í„°ë§
            if re.match(r'^[\d\s,\.\)]+$', content) and len(content) < 20:
                logger.warning(f"ë¶ˆì™„ì „í•œ ë‚´ìš©ìœ¼ë¡œ ê±´ë„ˆë›°ê¸°: ì œ{article_num}ì¡° (ë‚´ìš©: {content[:50]})")
                continue
            
            articles.append({
                "number": article_num,
                "title": article_title,
                "content": content
            })
            
            seen_numbers.add(article_num)
            logger.debug(f"ì¡°ë¬¸ ì¶”ì¶œ ì„±ê³µ: ì œ{article_num}ì¡° (ì œëª©: {article_title or 'ì—†ìŒ'}, ë‚´ìš© ê¸¸ì´: {len(content)})")
        
        # ì¡°ë¬¸ ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ ì •ë ¬
        articles.sort(key=lambda x: int(x["number"]))
        
        # ì¶”ì¶œëœ ì¡°ë¬¸ ë²ˆí˜¸ ëª©ë¡ ë¡œê¹…
        extracted_numbers = [a["number"] for a in articles]
        logger.info(f"ì¶”ì¶œëœ ì¡°ë¬¸ ìˆ˜: {len(articles)} (ì¤‘ë³µ ì œê±° í›„)")
        logger.info(f"ì¶”ì¶œëœ ì¡°ë¬¸ ë²ˆí˜¸: {', '.join(extracted_numbers)}")
        
        # ëˆ„ë½ëœ ì¡°ë¬¸ ë²ˆí˜¸ í™•ì¸ (1ë¶€í„° ìµœëŒ€ ì¡°ë¬¸ ë²ˆí˜¸ê¹Œì§€)
        if articles:
            max_num = max(int(a["number"]) for a in articles)
            all_numbers = set(str(i) for i in range(1, max_num + 1))
            extracted_set = set(extracted_numbers)
            missing = sorted(all_numbers - extracted_set, key=int)
            if missing:
                logger.warning(f"ëˆ„ë½ëœ ì¡°ë¬¸ ë²ˆí˜¸: {', '.join(missing)}")
        
        return articles
    
    def clean_content(self, content: str) -> str:
        """ì¡°ë¬¸ ë‚´ìš© ì •ì œ"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = re.sub(r'\s+', ' ', content)
        # ì¤„ë°”ê¿ˆ ì •ë¦¬
        content = re.sub(r'\n\s*\n', '\n', content)
        # ì•ë’¤ ê³µë°± ì œê±°
        content = content.strip()
        return content
    
    def determine_category(self, article_num: str, law_name: str) -> tuple[str, str]:
        """
        ì¡°ë¬¸ ë²ˆí˜¸ì™€ ë²•ë¥ ëª…ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ì™€ ì„œë¸Œì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            article_num: ì¡°ë¬¸ ë²ˆí˜¸
            law_name: ë²•ë¥ ëª…
            
        Returns:
            (category, sub_category) íŠœí”Œ
        """
        # í˜•ë²•ì˜ ê²½ìš°
        if law_name == "í˜•ë²•":
            num = int(article_num) if article_num.isdigit() else 0
            
            # ì´ì¹™ (1-72ì¡°)
            if 1 <= num <= 72:
                return ("í˜•ì‚¬", "ì´ì¹™")
            # ê°ì¹™
            elif 130 <= num <= 250:
                return ("í˜•ì‚¬", "ìƒëª…ê³¼ ì‹ ì²´ì— ëŒ€í•œ ì£„")
            elif 250 <= num <= 280:
                return ("í˜•ì‚¬", "ììœ ì— ëŒ€í•œ ì£„")
            elif 329 <= num <= 361:
                return ("í˜•ì‚¬", "ì¬ì‚°ì— ëŒ€í•œ ì£„")
            elif num == 347:
                return ("í˜•ì‚¬", "ì‚¬ê¸°")
            elif 362 <= num <= 365:
                return ("í˜•ì‚¬", "ì¥ë¬¼")
            elif 366 <= num <= 372:
                return ("í˜•ì‚¬", "ì†ê´´")
            else:
                return ("í˜•ì‚¬", "")
        
        # í˜•ì‚¬ì†Œì†¡ë²•ì˜ ê²½ìš°
        elif law_name == "í˜•ì‚¬ì†Œì†¡ë²•":
            return ("í˜•ì‚¬", "ì†Œì†¡ì ˆì°¨")
        
        # ê¸°ë³¸ê°’
        return ("í˜•ì‚¬", "")
    
    def extract_topics(self, content: str, title: str) -> List[str]:
        """ì¡°ë¬¸ ë‚´ìš©ì—ì„œ ì£¼ì œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        topics = []
        
        # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if title:
            keywords = ["ì‚¬ê¸°", "ì‚´ì¸", "ì ˆë„", "ê°•ë„", "ê°•ê°„", "íš¡ë ¹", "ì¥ë¬¼", "ì†ê´´"]
            for keyword in keywords:
                if keyword in title:
                    topics.append(keyword)
        
        # ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        content_keywords = ["ì¬ë¬¼", "ì¬ì‚°", "ì´ìµ", "ê¸°ë§", "í¸ì·¨"]
        for keyword in content_keywords:
            if keyword in content:
                if keyword not in topics:
                    topics.append(keyword)
        
        return topics
    
    def create_statute_json(
        self,
        law_name: str,
        article_num: str,
        title: str,
        content: str,
        updated_at: str = None
    ) -> Dict[str, Any]:
        """
        ì¡°ë¬¸ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            law_name: ë²•ë¥ ëª…
            article_num: ì¡°ë¬¸ ë²ˆí˜¸
            title: ì¡°ë¬¸ ì œëª©
            content: ì¡°ë¬¸ ë‚´ìš©
            updated_at: ê°œì •ì¼
            
        Returns:
            JSON í˜•ì‹ì˜ ì¡°ë¬¸ ë°ì´í„°
        """
        category, sub_category = self.determine_category(article_num, law_name)
        topics = self.extract_topics(content, title)
        
        # ID ìƒì„±: "statute-í˜•ë²•-347"
        doc_id = f"statute-{law_name}-{article_num}"
        
        # ì œëª© ìƒì„±: "í˜•ë²• ì œ347ì¡°(ì‚¬ê¸°)"
        if title:
            full_title = f"{law_name} ì œ{article_num}ì¡°({title})"
        else:
            full_title = f"{law_name} ì œ{article_num}ì¡°"
        
        # ë‚´ìš© ì •ì œ
        cleaned_content = self.clean_content(content)
        
        return {
            "id": doc_id,
            "category": category,
            "sub_category": sub_category,
            "type": "statute",
            "title": full_title,
            "content": cleaned_content,
            "metadata": {
                "law_name": law_name,
                "article_number": article_num,
                "topics": topics,
                "source": "ë²•ì œì²˜",
                "updated_at": updated_at or datetime.now().strftime("%Y-%m-%d")
            }
        }
    
    def save_article(self, law_name: str, article_data: Dict[str, Any]) -> Path:
        """
        ì¡°ë¬¸ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            law_name: ë²•ë¥ ëª…
            article_data: ì¡°ë¬¸ ë°ì´í„°
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # ë²•ë¥ ë³„ í´ë” ìƒì„±
        law_dir = self.output_dir / law_name
        law_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ëª…: "statute-í˜•ë²•-347.json"
        filename = f"{article_data['id']}.json"
        file_path = law_dir / filename
        
        # JSON íŒŒì¼ ì €ì¥
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(article_data, f, ensure_ascii=False, indent=2)
        
        return file_path
    
    def parse_and_save(self, pdf_path: Path, updated_at: str = None) -> List[Path]:
        """
        PDFë¥¼ íŒŒì‹±í•˜ì—¬ ì¡°ë¬¸ë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            updated_at: ê°œì •ì¼ (PDF íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ ì‹œë„)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"PDF íŒŒì‹± ì‹œì‘: {pdf_path}")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.parse_pdf_text(pdf_path)
        
        # ë²•ë¥ ëª… ì¶”ì¶œ (íŒŒì¼ëª… ìš°ì„ )
        law_name = self.extract_law_name(text, pdf_path)
        logger.info(f"ë²•ë¥ ëª…: {law_name}")
        
        # ê°œì •ì¼ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
        if not updated_at:
            match = re.search(r'\((\d{8})\)', pdf_path.name)
            if match:
                date_str = match.group(1)
                updated_at = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        # ì¡°ë¬¸ ì¶”ì¶œ (ë²•ë¥ ëª… ì „ë‹¬í•˜ì—¬ í•„í„°ë§ ê°€ëŠ¥)
        articles = self.extract_articles(text, law_name)
        logger.info(f"ì¶”ì¶œëœ ì¡°ë¬¸ ìˆ˜: {len(articles)}")
        
        # ê° ì¡°ë¬¸ì„ JSON íŒŒì¼ë¡œ ì €ì¥
        saved_files = []
        for article in articles:
            article_data = self.create_statute_json(
                law_name=law_name,
                article_num=article["number"],
                title=article.get("title"),
                content=article["content"],
                updated_at=updated_at
            )
            
            file_path = self.save_article(law_name, article_data)
            saved_files.append(file_path)
            
            logger.debug(f"ì €ì¥ ì™„ë£Œ: {file_path.name}")
        
        logger.info(f"ì´ {len(saved_files)}ê°œ ì¡°ë¬¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        return saved_files


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="í˜•ë²• PDFë¥¼ ì¡°ë¬¸ë³„ JSONìœ¼ë¡œ ë³€í™˜")
    parser.add_argument(
        "pdf_path",
        type=Path,
        help="PDF íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("data/collected/statutes"),
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/collected/statutes)"
    )
    parser.add_argument(
        "--updated-at",
        type=str,
        help="ê°œì •ì¼ (YYYY-MM-DD í˜•ì‹, íŒŒì¼ëª…ì—ì„œ ìë™ ì¶”ì¶œ ì‹œë„)"
    )
    
    args = parser.parse_args()
    
    if not args.pdf_path.exists():
        logger.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.pdf_path}")
        return
    
    # íŒŒì„œ ìƒì„± ë° ì‹¤í–‰
    parser_obj = StatutePDFParser(args.output_dir)
    saved_files = parser_obj.parse_and_save(args.pdf_path, args.updated_at)
    
    print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output_dir}")
    print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼ ìˆ˜: {len(saved_files)}")
    print(f"\nì²« 5ê°œ íŒŒì¼:")
    for file_path in saved_files[:5]:
        print(f"  - {file_path}")


if __name__ == "__main__":
    main()

