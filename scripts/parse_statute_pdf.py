"""í˜•ë²• PDFë¥¼ ì¡°ë¬¸ë³„ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸"""

import re
import json
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class StatutePDFParser:
    """í˜•ë²• PDF íŒŒì„œ"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def parse_pdf_text(self, pdf_path: Path) -> str:
        """
        PDF íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PDF í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        try:
            import PyPDF2
        except ImportError:
            logger.error("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install PyPDF2'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            raise
        
        text = ""
        with open(pdf_path, "rb") as file:
            pdf_reader = PyPDF2.PdfReader(file)
            for page in pdf_reader.pages:
                text += page.extract_text() + "\n"
        
        return text
    
    def extract_law_name(self, text: str) -> str:
        """ë²•ë¥ ëª… ì¶”ì¶œ"""
        # PDF ì²« ë¶€ë¶„ì—ì„œ ë²•ë¥ ëª… ì¶”ì¶œ
        # ì˜ˆ: "í˜•ë²•(ë²•ë¥ )(ì œ20908í˜¸)(20250408).pdf" -> "í˜•ë²•"
        patterns = [
            r"í˜•ë²•",
            r"í˜•ì‚¬ì†Œì†¡ë²•",
            r"ë¯¼ë²•",
            r"ë¯¼ì‚¬ì†Œì†¡ë²•",
        ]
        
        for pattern in patterns:
            if re.search(pattern, text[:500]):
                return pattern
        
        return "í˜•ë²•"  # ê¸°ë³¸ê°’
    
    def extract_articles(self, text: str) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ì—ì„œ ì¡°ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDFì—ì„œ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸
            
        Returns:
            ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        articles = []
        
        # ì¡°ë¬¸ íŒ¨í„´: "ì œXì¡°" ë˜ëŠ” "ì œXì¡°(ì œëª©)"
        # ì˜ˆ: "ì œ1ì¡°(ë²”ì£„ì˜ ì„±ë¦½ê³¼ ì²˜ë²Œ)", "ì œ347ì¡°(ì‚¬ê¸°)"
        article_pattern = r'ì œ(\d+)ì¡°(?:\(([^)]+)\))?'
        
        # ì¡°ë¬¸ìœ¼ë¡œ ë¶„í• 
        parts = re.split(article_pattern, text)
        
        current_article_num = None
        current_title = None
        current_content = ""
        
        for i, part in enumerate(parts):
            # ì¡°ë¬¸ ë²ˆí˜¸ì¸ ê²½ìš°
            if part.isdigit():
                # ì´ì „ ì¡°ë¬¸ ì €ì¥
                if current_article_num is not None:
                    articles.append({
                        "number": current_article_num,
                        "title": current_title,
                        "content": current_content.strip()
                    })
                
                current_article_num = part
                current_content = ""
                # ë‹¤ìŒ ë¶€ë¶„ì´ ì œëª©ì¸ì§€ í™•ì¸
                if i + 1 < len(parts) and parts[i + 1] and not parts[i + 1].isdigit():
                    if not parts[i + 1].startswith("ì œ"):
                        current_title = parts[i + 1].strip("()")
                    else:
                        current_title = None
                else:
                    current_title = None
            elif part and not part.startswith("ì œ") and current_article_num:
                # ì¡°ë¬¸ ë‚´ìš©
                current_content += part + "\n"
        
        # ë§ˆì§€ë§‰ ì¡°ë¬¸ ì €ì¥
        if current_article_num is not None:
            articles.append({
                "number": current_article_num,
                "title": current_title,
                "content": current_content.strip()
            })
        
        return articles
    
    def clean_content(self, content: str) -> str:
        """ì¡°ë¬¸ ë‚´ìš© ì •ì œ"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = re.sub(r'\s+', ' ', content)
        # ì¤„ë°”ê¿ˆ ì •ë¦¬
        content = re.sub(r'\n\s*\n', '\n', content)
        # ì•ë’¤ ê³µë°± ì œê±°
        content = content.strip()
        return content
    
    def determine_category(self, article_num: str, law_name: str) -> tuple[str, str]:
        """
        ì¡°ë¬¸ ë²ˆí˜¸ì™€ ë²•ë¥ ëª…ìœ¼ë¡œ ì¹´í…Œê³ ë¦¬ì™€ ì„œë¸Œì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            article_num: ì¡°ë¬¸ ë²ˆí˜¸
            law_name: ë²•ë¥ ëª…
            
        Returns:
            (category, sub_category) íŠœí”Œ
        """
        # í˜•ë²•ì˜ ê²½ìš°
        if law_name == "í˜•ë²•":
            num = int(article_num) if article_num.isdigit() else 0
            
            # ì´ì¹™ (1-72ì¡°)
            if 1 <= num <= 72:
                return ("í˜•ì‚¬", "ì´ì¹™")
            # ê°ì¹™
            elif 130 <= num <= 250:
                return ("í˜•ì‚¬", "ìƒëª…ê³¼ ì‹ ì²´ì— ëŒ€í•œ ì£„")
            elif 250 <= num <= 280:
                return ("í˜•ì‚¬", "ììœ ì— ëŒ€í•œ ì£„")
            elif 329 <= num <= 361:
                return ("í˜•ì‚¬", "ì¬ì‚°ì— ëŒ€í•œ ì£„")
            elif num == 347:
                return ("í˜•ì‚¬", "ì‚¬ê¸°")
            elif 362 <= num <= 365:
                return ("í˜•ì‚¬", "ì¥ë¬¼")
            elif 366 <= num <= 372:
                return ("í˜•ì‚¬", "ì†ê´´")
            else:
                return ("í˜•ì‚¬", "")
        
        # í˜•ì‚¬ì†Œì†¡ë²•ì˜ ê²½ìš°
        elif law_name == "í˜•ì‚¬ì†Œì†¡ë²•":
            return ("í˜•ì‚¬", "ì†Œì†¡ì ˆì°¨")
        
        # ê¸°ë³¸ê°’
        return ("í˜•ì‚¬", "")
    
    def extract_topics(self, content: str, title: str) -> List[str]:
        """ì¡°ë¬¸ ë‚´ìš©ì—ì„œ ì£¼ì œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        topics = []
        
        # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        if title:
            keywords = ["ì‚¬ê¸°", "ì‚´ì¸", "ì ˆë„", "ê°•ë„", "ê°•ê°„", "íš¡ë ¹", "ì¥ë¬¼", "ì†ê´´"]
            for keyword in keywords:
                if keyword in title:
                    topics.append(keyword)
        
        # ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
        content_keywords = ["ì¬ë¬¼", "ì¬ì‚°", "ì´ìµ", "ê¸°ë§", "í¸ì·¨"]
        for keyword in content_keywords:
            if keyword in content:
                if keyword not in topics:
                    topics.append(keyword)
        
        return topics
    
    def create_statute_json(
        self,
        law_name: str,
        article_num: str,
        title: str,
        content: str,
        updated_at: str = None
    ) -> Dict[str, Any]:
        """
        ì¡°ë¬¸ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            law_name: ë²•ë¥ ëª…
            article_num: ì¡°ë¬¸ ë²ˆí˜¸
            title: ì¡°ë¬¸ ì œëª©
            content: ì¡°ë¬¸ ë‚´ìš©
            updated_at: ê°œì •ì¼
            
        Returns:
            JSON í˜•ì‹ì˜ ì¡°ë¬¸ ë°ì´í„°
        """
        category, sub_category = self.determine_category(article_num, law_name)
        topics = self.extract_topics(content, title)
        
        # ID ìƒì„±: "statute-í˜•ë²•-347"
        doc_id = f"statute-{law_name}-{article_num}"
        
        # ì œëª© ìƒì„±: "í˜•ë²• ì œ347ì¡°(ì‚¬ê¸°)"
        if title:
            full_title = f"{law_name} ì œ{article_num}ì¡°({title})"
        else:
            full_title = f"{law_name} ì œ{article_num}ì¡°"
        
        # ë‚´ìš© ì •ì œ
        cleaned_content = self.clean_content(content)
        
        return {
            "id": doc_id,
            "category": category,
            "sub_category": sub_category,
            "type": "statute",
            "title": full_title,
            "content": cleaned_content,
            "metadata": {
                "law_name": law_name,
                "article_number": article_num,
                "topics": topics,
                "source": "ë²•ì œì²˜",
                "updated_at": updated_at or datetime.now().strftime("%Y-%m-%d")
            }
        }
    
    def save_article(self, law_name: str, article_data: Dict[str, Any]) -> Path:
        """
        ì¡°ë¬¸ì„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            law_name: ë²•ë¥ ëª…
            article_data: ì¡°ë¬¸ ë°ì´í„°
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # ë²•ë¥ ë³„ í´ë” ìƒì„±
        law_dir = self.output_dir / law_name
        law_dir.mkdir(parents=True, exist_ok=True)
        
        # íŒŒì¼ëª…: "statute-í˜•ë²•-347.json"
        filename = f"{article_data['id']}.json"
        file_path = law_dir / filename
        
        # JSON íŒŒì¼ ì €ì¥
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(article_data, f, ensure_ascii=False, indent=2)
        
        return file_path
    
    def parse_and_save(self, pdf_path: Path, updated_at: str = None) -> List[Path]:
        """
        PDFë¥¼ íŒŒì‹±í•˜ì—¬ ì¡°ë¬¸ë³„ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            updated_at: ê°œì •ì¼ (PDF íŒŒì¼ëª…ì—ì„œ ì¶”ì¶œ ì‹œë„)
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"PDF íŒŒì‹± ì‹œì‘: {pdf_path}")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.parse_pdf_text(pdf_path)
        
        # ë²•ë¥ ëª… ì¶”ì¶œ
        law_name = self.extract_law_name(text)
        logger.info(f"ë²•ë¥ ëª…: {law_name}")
        
        # ê°œì •ì¼ ì¶”ì¶œ (íŒŒì¼ëª…ì—ì„œ)
        if not updated_at:
            match = re.search(r'\((\d{8})\)', pdf_path.name)
            if match:
                date_str = match.group(1)
                updated_at = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        
        # ì¡°ë¬¸ ì¶”ì¶œ
        articles = self.extract_articles(text)
        logger.info(f"ì¶”ì¶œëœ ì¡°ë¬¸ ìˆ˜: {len(articles)}")
        
        # ê° ì¡°ë¬¸ì„ JSON íŒŒì¼ë¡œ ì €ì¥
        saved_files = []
        for article in articles:
            article_data = self.create_statute_json(
                law_name=law_name,
                article_num=article["number"],
                title=article.get("title"),
                content=article["content"],
                updated_at=updated_at
            )
            
            file_path = self.save_article(law_name, article_data)
            saved_files.append(file_path)
            
            logger.debug(f"ì €ì¥ ì™„ë£Œ: {file_path.name}")
        
        logger.info(f"ì´ {len(saved_files)}ê°œ ì¡°ë¬¸ íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        return saved_files


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="í˜•ë²• PDFë¥¼ ì¡°ë¬¸ë³„ JSONìœ¼ë¡œ ë³€í™˜")
    parser.add_argument(
        "pdf_path",
        type=Path,
        help="PDF íŒŒì¼ ê²½ë¡œ"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("data/collected/statutes"),
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/collected/statutes)"
    )
    parser.add_argument(
        "--updated-at",
        type=str,
        help="ê°œì •ì¼ (YYYY-MM-DD í˜•ì‹, íŒŒì¼ëª…ì—ì„œ ìë™ ì¶”ì¶œ ì‹œë„)"
    )
    
    args = parser.parse_args()
    
    if not args.pdf_path.exists():
        logger.error(f"PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.pdf_path}")
        return
    
    # íŒŒì„œ ìƒì„± ë° ì‹¤í–‰
    parser_obj = StatutePDFParser(args.output_dir)
    saved_files = parser_obj.parse_and_save(args.pdf_path, args.updated_at)
    
    print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
    print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output_dir}")
    print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼ ìˆ˜: {len(saved_files)}")
    print(f"\nì²« 5ê°œ íŒŒì¼:")
    for file_path in saved_files[:5]:
        print(f"  - {file_path}")


if __name__ == "__main__":
    main()

