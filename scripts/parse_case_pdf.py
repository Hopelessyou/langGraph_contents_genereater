"""íŒë¡€ PDFë¥¼ JSON íŒŒì¼ë¡œ ë³€í™˜í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸"""

import re
import json
from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime
import logging

logging.basicConfig(
    level=logging.INFO,
    format='%(levelname)s:%(name)s:%(message)s'
)
logger = logging.getLogger(__name__)


class CasePDFParser:
    """íŒë¡€ PDF íŒŒì„œ"""
    
    def __init__(self, output_dir: Path):
        self.output_dir = output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
    def parse_pdf_text(self, pdf_path: Path) -> str:
        """
        PDF íŒŒì¼ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        PyPDF2 ì‹¤íŒ¨ ì‹œ pdfplumberë¡œ ìë™ ì „í™˜í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            PDF í…ìŠ¤íŠ¸ ë‚´ìš©
        """
        # ë°©ë²• 1: PyPDF2 ì‹œë„
        try:
            import PyPDF2
            text = ""
            with open(pdf_path, "rb") as file:
                pdf_reader = PyPDF2.PdfReader(file)
                for page in pdf_reader.pages:
                    text += page.extract_text() + "\n"
            
            if text.strip():  # í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆëŠ”ì§€ í™•ì¸
                return text
            else:
                logger.warning(f"PyPDF2ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. pdfplumberë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
                raise ValueError("PyPDF2 failed to extract text")
                
        except (ImportError, Exception) as e:
            if isinstance(e, ImportError):
                logger.warning("PyPDF2ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pdfplumberë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
            else:
                logger.warning(f"PyPDF2 ì˜¤ë¥˜ ë°œìƒ ({str(e)}). pdfplumberë¡œ ì‹œë„í•©ë‹ˆë‹¤.")
        
        # ë°©ë²• 2: pdfplumber ì‹œë„ (fallback)
        try:
            import pdfplumber
            text = ""
            with pdfplumber.open(pdf_path) as pdf:
                for page in pdf.pages:
                    page_text = page.extract_text()
                    if page_text:
                        text += page_text + "\n"
            
            if text.strip():
                logger.info("pdfplumberë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                return text
            else:
                raise ValueError("pdfplumber failed to extract text")
                
        except ImportError:
            logger.error("pdfplumberê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install pdfplumber'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
            raise
        except Exception as e:
            logger.error(f"pdfplumber ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
            # ë°©ë²• 3: pymupdf (fitz) ì‹œë„ (ìµœì¢… fallback)
            try:
                import fitz  # pymupdf
                text = ""
                doc = fitz.open(pdf_path)
                for page in doc:
                    page_text = page.get_text()
                    if page_text:
                        text += page_text + "\n"
                doc.close()
                
                if text.strip():
                    logger.info("pymupdfë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ")
                    return text
                else:
                    raise ValueError("pymupdf failed to extract text")
                    
            except ImportError:
                logger.error("pymupdfê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. 'pip install pymupdf'ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
                raise
            except Exception as e2:
                logger.error(f"ëª¨ë“  PDF ë¼ì´ë¸ŒëŸ¬ë¦¬ ì‹¤íŒ¨: PyPDF2, pdfplumber, pymupdf ëª¨ë‘ ì‹¤íŒ¨")
                raise Exception(f"PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e2)}")
    
    def extract_case_number(self, text: str, pdf_path: Path = None) -> Optional[str]:
        """
        ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ (íŒŒì¼ëª…ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„)
            
        Returns:
            ì‚¬ê±´ë²ˆí˜¸ (ì˜ˆ: "2023ë„11234")
        """
        # 1. íŒŒì¼ëª…ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ ì‹œë„ (ìš°ì„ ìˆœìœ„ 1)
        if pdf_path:
            filename = pdf_path.stem  # í™•ì¥ì ì œê±°
            # íŒ¨í„´: "íŒë¡€_2012ë…¸856", "2010ë„12928", "íŒë¡€-2012ë…¸856", "2016ê³ í•©209" ë“±
            filename_patterns = [
                r'(\d{4}ê³ í•©\d+)',  # í•˜ê¸‰ì‹¬ í˜•ì‚¬í•©ì˜: 2016ê³ í•©209
                r'(\d{4}ê³ ë‹¨\d+)',  # í•˜ê¸‰ì‹¬ í˜•ì‚¬ë‹¨ë…: 2016ê³ ë‹¨123
                r'(\d{4}ê³ ê¸°\d+)',  # í•˜ê¸‰ì‹¬ í˜•ì‚¬ê¸°ì†Œ: 2016ê³ ê¸°456
                r'(\d{4}ì´ˆê¸°\d+)',  # í•˜ê¸‰ì‹¬ í˜•ì‚¬ê¸°ì†Œ: 2016ì´ˆê¸°1295
                r'(\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€ë…¸]\d+)',  # 2012ë…¸856, 2010ë„12928
                r'íŒë¡€[_-]?(\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€ë…¸]\d+)',  # íŒë¡€_2012ë…¸856
            ]
            
            for pattern in filename_patterns:
                match = re.search(pattern, filename)
                if match:
                    case_number = match.group(1)
                    logger.info(f"íŒŒì¼ëª…ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ: {case_number}")
                    return case_number
        
        # 2. PDF í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„ 2)
        # ì‚¬ê±´ë²ˆí˜¸ íŒ¨í„´: ì—°ë„ + ë²•ì›ì½”ë“œ + ë²ˆí˜¸
        # ì˜ˆ: "2023ë„11234", "2023ê°€ë‹¨12345", "2023ë‚˜12345", "2012ë…¸856"
        # í•˜ê¸‰ì‹¬: "2016ê³ í•©209", "2016ê³ ë‹¨123", "2016ê³ ê¸°456", "2016ì´ˆê¸°1295"
        patterns = [
            r'(\d{4}ë…¸\d+)',  # í•­ì†Œ: 2012ë…¸856 (íŒŒì¼ëª…ê³¼ ì¼ì¹˜í•˜ëŠ” ê²½ìš° ìš°ì„ )
            r'(\d{4}ë„\d+)',  # í˜•ì‚¬: 2023ë„11234
            r'(\d{4}ê³ í•©\d+)',  # í˜•ì‚¬í•©ì˜: 2016ê³ í•©209 (í•˜ê¸‰ì‹¬)
            r'(\d{4}ê³ ë‹¨\d+)',  # í˜•ì‚¬ë‹¨ë…: 2016ê³ ë‹¨123 (í•˜ê¸‰ì‹¬)
            r'(\d{4}ê³ ê¸°\d+)',  # í˜•ì‚¬ê¸°ì†Œ: 2016ê³ ê¸°456 (í•˜ê¸‰ì‹¬)
            r'(\d{4}ì´ˆê¸°\d+)',  # í˜•ì‚¬ê¸°ì†Œ: 2016ì´ˆê¸°1295 (í•˜ê¸‰ì‹¬)
            r'(\d{4}ê°€ë‹¨\d+)',  # ê°€ì‚¬: 2023ê°€ë‹¨12345
            r'(\d{4}ë‚˜\d+)',  # ë¯¼ì‚¬: 2023ë‚˜12345
            r'(\d{4}ë‹¤\d+)',  # í–‰ì •: 2023ë‹¤12345
            r'(\d{4}ë¼\d+)',  # íŠ¹í—ˆ: 2023ë¼12345
            r'(\d{4}ë§ˆ\d+)',  # ì¡°ì„¸: 2023ë§ˆ12345
            r'(\d{4}ë°”\d+)',  # ì„ ê±°: 2023ë°”12345
            r'(\d{4}ì‚¬\d+)',  # ì§€ë°©ìì¹˜: 2023ì‚¬12345
            r'(\d{4}ì•„\d+)',  # ë…¸ë™: 2023ì•„12345
            r'(\d{4}ì\d+)',  # í•´ìƒ: 2023ì12345
            r'(\d{4}ì°¨\d+)',  # ê±´ì„¤: 2023ì°¨12345
            r'(\d{4}ì¹´\d+)',  # ê¸ˆìœµ: 2023ì¹´12345
            r'(\d{4}íƒ€\d+)',  # ê¸°íƒ€: 2023íƒ€12345
        ]
        
        for pattern in patterns:
            match = re.search(pattern, text[:2000])  # ì•ë¶€ë¶„ì—ì„œ ê²€ìƒ‰
            if match:
                case_number = match.group(1)
                logger.info(f"í…ìŠ¤íŠ¸ì—ì„œ ì‚¬ê±´ë²ˆí˜¸ ì¶”ì¶œ: {case_number}")
                return case_number
        
        logger.warning("ì‚¬ê±´ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def extract_court(self, text: str, case_number: Optional[str] = None) -> str:
        """
        ë²•ì›ëª…ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            case_number: ì‚¬ê±´ë²ˆí˜¸ (ë²•ì› ì¶”ë¡ ì— ì‚¬ìš©)
            
        Returns:
            ë²•ì›ëª… (ê¸°ë³¸ê°’: "ëŒ€ë²•ì›")
        """
        # ì‚¬ê±´ë²ˆí˜¸ë¡œ ë²•ì› ì¶”ë¡ 
        if case_number:
            # "ë…¸"ëŠ” ê³ ë“±ë²•ì› í•­ì†Œì‚¬ê±´
            if "ë…¸" in case_number:
                # ê³ ë“±ë²•ì› íŒ¨í„´ ì°¾ê¸°
                high_court_patterns = [
                    r'ì„œìš¸ê³ ë“±ë²•ì›',
                    r'ë¶€ì‚°ê³ ë“±ë²•ì›',
                    r'ëŒ€ì „ê³ ë“±ë²•ì›',
                    r'ëŒ€êµ¬ê³ ë“±ë²•ì›',
                    r'ê´‘ì£¼ê³ ë“±ë²•ì›',
                ]
                for pattern in high_court_patterns:
                    match = re.search(pattern, text[:2000])
                    if match:
                        court = match.group(0)
                        logger.info(f"ì‚¬ê±´ë²ˆí˜¸ì™€ í…ìŠ¤íŠ¸ë¡œ ë²•ì›ëª… ì¶”ì¶œ: {court}")
                        return court
                # ê³ ë“±ë²•ì›ì„ ì°¾ì§€ ëª»í•˜ë©´ ê¸°ë³¸ê°’
                logger.info("ê³ ë“±ë²•ì›ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ 'ëŒ€ë²•ì›'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                return "ëŒ€ë²•ì›"
        
        # ë²•ì›ëª… íŒ¨í„´
        courts = [
            "ëŒ€ë²•ì› ì „ì›í•©ì˜ì²´",
            "ëŒ€ë²•ì›",
            "ì„œìš¸ê³ ë“±ë²•ì›",
            "ë¶€ì‚°ê³ ë“±ë²•ì›",
            "ëŒ€ì „ê³ ë“±ë²•ì›",
            "ëŒ€êµ¬ê³ ë“±ë²•ì›",
            "ê´‘ì£¼ê³ ë“±ë²•ì›",
            "ì„œìš¸ì¤‘ì•™ì§€ë°©ë²•ì›",
            "ì„œìš¸ë™ë¶€ì§€ë°©ë²•ì›",
            "ì„œìš¸ì„œë¶€ì§€ë°©ë²•ì›",
            "ì„œìš¸ë‚¨ë¶€ì§€ë°©ë²•ì›",
            "ì„œìš¸ë¶ë¶€ì§€ë°©ë²•ì›",
            "ê³ ë“±êµ°ì‚¬ë²•ì›",
            "ê´‘ì£¼ì§€ë°©ë²•ì›",
            "ëŒ€êµ¬ì§€ë²•",
            "ë¶€ì‚°ì§€ë²•",
            "ëŒ€ì „ì§€ë²•",
            "ì¸ì²œì§€ë²•",
            "ìš¸ì‚°ì§€ë°©ë²•ì›",
            "ì˜ì •ë¶€ì§€ë°©ë²•ì›",
            "ì²­ì£¼ì§€ë°©ë²•ì›",
            "ì²œì•ˆì§€ë°©ë²•ì›",
            "ì¶˜ì²œì§€ë°©ë²•ì›",
            "ì¶©ì£¼ì§€ë°©ë²•ì›",
            "ì „ì£¼ì§€ë°©ë²•ì›",
            "ì „ë‚¨ì§€ë°©ë²•ì›",
            "ì „ë¶ì§€ë°©ë²•ì›",
            "ì œì£¼ì§€ë°©ë²•ì›",
            "ì œì£¼ë„ì§€ë°©ë²•ì›",
            "ì œì£¼ë„ì§€ë°©ë²•ì›"
        ]
        
        for court in courts:
            if court in text[:2000]:  # ì•ë¶€ë¶„ì—ì„œ ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€
                logger.info(f"ë²•ì›ëª… ì¶”ì¶œ: {court}")
                return court
        
        logger.info("ë²•ì›ëª…ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ê¸°ë³¸ê°’ 'ëŒ€ë²•ì›'ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return "ëŒ€ë²•ì›"
    
    def extract_year(self, text: str, case_number: Optional[str] = None, judgment_date: Optional[str] = None) -> Optional[int]:
        """
        íŒê²° ì—°ë„ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            case_number: ì‚¬ê±´ë²ˆí˜¸ (ì—°ë„ ì¶”ì¶œì— ì‚¬ìš©)
            judgment_date: íŒê²°ì¼ (YYYY-MM-DD í˜•ì‹, ìš°ì„ ìˆœìœ„ 1)
            
        Returns:
            ì—°ë„ (ì˜ˆ: 2023)
        """
        # 1. íŒê²°ì¼ì—ì„œ ì—°ë„ ì¶”ì¶œ (ìµœìš°ì„ )
        if judgment_date:
            match = re.match(r'(\d{4})', judgment_date)
            if match:
                year = int(match.group(1))
                if 2000 <= year <= datetime.now().year:
                    logger.info(f"íŒê²°ì¼ì—ì„œ ì—°ë„ ì¶”ì¶œ: {year}")
                    return year
        
        # 2. ì‚¬ê±´ë²ˆí˜¸ì—ì„œ ì—°ë„ ì¶”ì¶œ
        if case_number:
            match = re.match(r'(\d{4})', case_number)
            if match:
                year = int(match.group(1))
                if 2000 <= year <= datetime.now().year:
                    logger.info(f"ì‚¬ê±´ë²ˆí˜¸ì—ì„œ ì—°ë„ ì¶”ì¶œ: {year}")
                    return year
        
        # 3. í…ìŠ¤íŠ¸ì—ì„œ íŒê²°ì¼ íŒ¨í„´ìœ¼ë¡œ ì—°ë„ ê²€ìƒ‰
        date_patterns = [
            r'(\d{4})\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ ',  # 2017. 2. 17. ì„ ê³ 
            r'(\d{4})ë…„\s*\d{1,2}ì›”\s*\d{1,2}ì¼',  # 2023ë…„ 1ì›” 1ì¼
            r'íŒê²°\s*:\s*(\d{4})',  # íŒê²°: 2023
            r'ì„ ê³ \s*:\s*(\d{4})',  # ì„ ê³ : 2023
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text[:3000])  # ê²€ìƒ‰ ë²”ìœ„ í™•ëŒ€
            if match:
                year = int(match.group(1))
                if 2000 <= year <= datetime.now().year:
                    logger.info(f"í…ìŠ¤íŠ¸ì—ì„œ ì—°ë„ ì¶”ì¶œ: {year}")
                    return year
        
        # í˜„ì¬ ì—°ë„ ì‚¬ìš©
        current_year = datetime.now().year
        logger.warning(f"ì—°ë„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ í˜„ì¬ ì—°ë„ {current_year}ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return current_year
    
    def extract_judgment_date(self, text: str) -> Optional[str]:
        """
        íŒê²°ì¼ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            íŒê²°ì¼ (YYYY-MM-DD í˜•ì‹) ë˜ëŠ” None
        """
        # íŒê²°ì¼ íŒ¨í„´: "2010. 12. 9." ë˜ëŠ” "2010ë…„ 12ì›” 9ì¼"
        date_patterns = [
            r'(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.',  # 2010. 12. 9.
            r'(\d{4})\s*ë…„\s*(\d{1,2})\s*ì›”\s*(\d{1,2})\s*ì¼',  # 2010ë…„ 12ì›” 9ì¼
            r'íŒê²°ì¼[:\s]*(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})',  # íŒê²°ì¼: 2010. 12. 9
            r'ì„ ê³ ì¼[:\s]*(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})',  # ì„ ê³ ì¼: 2010. 12. 9
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, text[:3000])
            if match:
                year = int(match.group(1))
                month = int(match.group(2))
                day = int(match.group(3))
                
                if 2000 <= year <= datetime.now().year and 1 <= month <= 12 and 1 <= day <= 31:
                    date_str = f"{year}-{month:02d}-{day:02d}"
                    logger.info(f"íŒê²°ì¼ ì¶”ì¶œ: {date_str}")
                    return date_str
        
        logger.warning("íŒê²°ì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def extract_panji_items(self, text: str) -> List[str]:
        """
        íŒì‹œì‚¬í•­ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            íŒì‹œì‚¬í•­ ë¦¬ìŠ¤íŠ¸
        """
        panji_items = []
        
        # ã€íŒì‹œì‚¬í•­ã€‘ ì„¹ì…˜ ì°¾ê¸°
        panji_pattern = r'ã€?\s*íŒì‹œì‚¬í•­\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)'
        match = re.search(panji_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            panji_section = match.group(1)
            
            # [1], [2] ë“±ìœ¼ë¡œ ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ í•­ëª© ì¶”ì¶œ
            item_pattern = r'\[(\d+)\]\s*(.+?)(?=\n\s*\[|\n\n|$)'
            items = re.findall(item_pattern, panji_section, re.DOTALL)
            
            for num, content in items:
                item_text = f"[{num}] {content.strip()}"
                # ë„ˆë¬´ ê¸´ ê²½ìš° ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
                if len(item_text) > 500:
                    item_text = item_text[:500] + "..."
                panji_items.append(item_text)
            
            if panji_items:
                logger.info(f"íŒì‹œì‚¬í•­ {len(panji_items)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
            else:
                # ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° ì „ì²´ ì„¹ì…˜ì„ í•˜ë‚˜ì˜ í•­ëª©ìœ¼ë¡œ
                panji_text = panji_section.strip()
                if len(panji_text) > 1000:
                    panji_text = panji_text[:1000] + "..."
                if panji_text:
                    panji_items.append(panji_text)
                    logger.info("íŒì‹œì‚¬í•­ 1ê°œ ì¶”ì¶œ ì™„ë£Œ (ë²ˆí˜¸ ì—†ìŒ)")
        else:
            # ê³ ë“±ë²•ì› íŒê²°ì˜ ê²½ìš° íŒì‹œì‚¬í•­ ì„¹ì…˜ì´ ì—†ì„ ìˆ˜ ìˆìŒ
            # í…ìŠ¤íŠ¸ì—ì„œ íŒì‹œì‚¬í•­ íŒ¨í„´ ì§ì ‘ ì°¾ê¸° ì‹œë„
            # "íŒì‹œì‚¬í•­", "íŒì‹œ", "ìš”ì§€" ë“±ì˜ í‚¤ì›Œë“œê°€ ìˆëŠ” ë¬¸ì¥ ì°¾ê¸°
            panji_keywords = ['íŒì‹œì‚¬í•­', 'íŒì‹œ', 'ìš”ì§€']
            found_any = False
            
            for keyword in panji_keywords:
                if keyword in text[:1000]:
                    found_any = True
                    break
            
            if not found_any:
                logger.debug("íŒì‹œì‚¬í•­ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê³ ë“±ë²•ì› íŒê²°ì˜ ê²½ìš° ì •ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
            else:
                logger.warning("íŒì‹œì‚¬í•­ ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        
        return panji_items
    
    def extract_reference_articles(self, text: str) -> List[str]:
        """
        ì°¸ì¡°ì¡°ë¬¸ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            ì°¸ì¡°ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        articles = []
        seen_articles = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        # ã€ì°¸ì¡°ì¡°ë¬¸ã€‘ ì„¹ì…˜ ì°¾ê¸°
        ref_pattern = r'ã€?\s*ì°¸ì¡°ì¡°ë¬¸\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)'
        match = re.search(ref_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            ref_section = match.group(1)
            
            # [1], [2] ë“±ìœ¼ë¡œ ë²ˆí˜¸ê°€ ë§¤ê²¨ì§„ í•­ëª© ì¶”ì¶œ
            item_pattern = r'\[(\d+)\]\s*(.+?)(?=\n\s*\[|\n\n|$)'
            items = re.findall(item_pattern, ref_section, re.DOTALL)
            
            for num, content in items:
                article_text = content.strip()
                if article_text and article_text not in seen_articles:
                    articles.append(article_text)
                    seen_articles.add(article_text)
            
            if not articles:
                # ë²ˆí˜¸ê°€ ì—†ëŠ” ê²½ìš° ì¡°ë¬¸ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
                article_patterns = [
                    r'í˜•ë²•\s*ì œ\d+ì¡°',
                    r'íŠ¹ì •ê²½ì œë²”ì£„\s*ê°€ì¤‘ì²˜ë²Œ\s*ë“±ì—\s*ê´€í•œ\s*ë²•ë¥ \s*ì œ\d+ì¡°',
                    r'í˜•ì‚¬ì†Œì†¡ë²•\s*ì œ\d+ì¡°',
                    r'ë¯¼ë²•\s*ì œ\d+ì¡°',
                    r'ì œ\d+ì¡°',
                ]
                
                for pattern in article_patterns:
                    matches = re.findall(pattern, ref_section)
                    for match_text in matches:
                        if match_text not in seen_articles:
                            articles.append(match_text)
                            seen_articles.add(match_text)
            
            if articles:
                logger.info(f"ì°¸ì¡°ì¡°ë¬¸ {len(articles)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        else:
            # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ ì¡°ë¬¸ íŒ¨í„´ ì°¾ê¸°
            article_patterns = [
                r'í˜•ë²•\s*ì œ\d+ì¡°',
                r'íŠ¹ì •ê²½ì œë²”ì£„\s*ê°€ì¤‘ì²˜ë²Œ\s*ë“±ì—\s*ê´€í•œ\s*ë²•ë¥ \s*ì œ\d+ì¡°',
                r'í˜•ì‚¬ì†Œì†¡ë²•\s*ì œ\d+ì¡°',
            ]
            
            for pattern in article_patterns:
                matches = re.findall(pattern, text)
                for match_text in matches:
                    if match_text not in seen_articles:
                        articles.append(match_text)
                        seen_articles.add(match_text)
            
            if articles:
                logger.info(f"ì°¸ì¡°ì¡°ë¬¸ {len(articles)}ê°œ ì¶”ì¶œ ì™„ë£Œ (í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ)")
            else:
                logger.debug("ì°¸ì¡°ì¡°ë¬¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê³ ë“±ë²•ì› íŒê²°ì˜ ê²½ìš° ì •ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        return articles
    
    def extract_reference_cases(self, text: str) -> List[str]:
        """
        ì°¸ì¡°íŒë¡€ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            ì°¸ì¡°íŒë¡€ ë¦¬ìŠ¤íŠ¸
        """
        cases = []
        seen_cases = set()  # ì¤‘ë³µ ì œê±°ìš©
        
        # ã€ì°¸ì¡°íŒë¡€ã€‘ ì„¹ì…˜ ì°¾ê¸°
        ref_pattern = r'ã€?\s*ì°¸ì¡°íŒë¡€\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)'
        match = re.search(ref_pattern, text, re.DOTALL | re.IGNORECASE)
        
        if match:
            ref_section = match.group(1)
            
            # íŒë¡€ íŒ¨í„´: "ëŒ€ë²•ì› 2007. 4. 19. ì„ ê³  2005ë„7288 ì „ì›í•©ì˜ì²´ íŒê²°"
            case_patterns = [
                r'ëŒ€ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+\s*[^/]+',
                r'ëŒ€ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+',
                r'ì„œìš¸ê³ ë“±ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+',
                r'ë¶€ì‚°ê³ ë“±ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+',
            ]
            
            for pattern in case_patterns:
                matches = re.findall(pattern, ref_section)
                for case in matches:
                    case_clean = case.strip()
                    if case_clean and case_clean not in seen_cases:
                        cases.append(case_clean)
                        seen_cases.add(case_clean)
            
            if cases:
                logger.info(f"ì°¸ì¡°íŒë¡€ {len(cases)}ê°œ ì¶”ì¶œ ì™„ë£Œ")
        else:
            # ì„¹ì…˜ì´ ì—†ëŠ” ê²½ìš° í…ìŠ¤íŠ¸ ì „ì²´ì—ì„œ íŒë¡€ íŒ¨í„´ ì°¾ê¸°
            case_patterns = [
                r'ëŒ€ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+',
                r'ì„œìš¸ê³ ë“±ë²•ì›\s*\d{4}\.\s*\d{1,2}\.\s*\d{1,2}\.\s*ì„ ê³ \s*\d{4}[ë„ë‚˜ê°€ë‹¤ë¼ë§ˆë°”ì‚¬ì•„ìì°¨ì¹´íƒ€]\d+',
            ]
            
            for pattern in case_patterns:
                matches = re.findall(pattern, text)
                for case in matches:
                    case_clean = case.strip()
                    if case_clean and case_clean not in seen_cases:
                        cases.append(case_clean)
                        seen_cases.add(case_clean)
            
            if cases:
                logger.info(f"ì°¸ì¡°íŒë¡€ {len(cases)}ê°œ ì¶”ì¶œ ì™„ë£Œ (í…ìŠ¤íŠ¸ì—ì„œ ì§ì ‘ ì¶”ì¶œ)")
            else:
                logger.debug("ì°¸ì¡°íŒë¡€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ê³ ë“±ë²•ì› íŒê²°ì˜ ê²½ìš° ì •ìƒì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤)")
        
        return cases
    
    def extract_holding(self, text: str, judgment_section: str = "") -> str:
        """
        íŒê²° ìš”ì§€ë¥¼ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
        í•˜ê¸‰ì‹¬ íŒë¡€ì˜ ê²½ìš° íŒê²° ìš”ì§€ ì„¹ì…˜ì´ ì—†ì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
        íŒë‹¨ ì„¹ì…˜ì˜ ìš”ì•½ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            judgment_section: íŒë‹¨ ì„¹ì…˜ ë‚´ìš© (í•˜ê¸‰ì‹¬ íŒë¡€ìš©)
            
        Returns:
            ì •ë¦¬ëœ íŒê²° ìš”ì§€
        """
        # íŒê²° ìš”ì§€ ì„¹ì…˜ ì°¾ê¸°
        holding_patterns = [
            r'ã€?\s*íŒê²°\s*ìš”ì§€\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            r'ã€?\s*ìš”\s*ì§€\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
        ]
        
        for pattern in holding_patterns:
            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            if match:
                holding = match.group(1).strip()
                # ì •ì œ
                holding = self.clean_section_content(holding)
                if holding:
                    # ë„ˆë¬´ ê¸´ ê²½ìš° ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
                    if len(holding) > 1000:
                        holding = holding[:1000] + "..."
                    logger.info(f"íŒê²° ìš”ì§€ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(holding)})")
                    return holding
        
        # í•˜ê¸‰ì‹¬ íŒë¡€: íŒê²° ìš”ì§€ê°€ ì—†ì„ ê²½ìš° íŒë‹¨ ì„¹ì…˜ì˜ ìš”ì•½ ì‚¬ìš©
        if judgment_section:
            # íŒë‹¨ ì„¹ì…˜ì˜ ì²« ë¶€ë¶„ì„ ìš”ì§€ë¡œ ì‚¬ìš© (ìµœëŒ€ 500ì)
            holding = judgment_section.strip()
            holding = self.clean_section_content(holding)
            if holding:
                # ì²« ë¬¸ë‹¨ ë˜ëŠ” ì²« 3-5ë¬¸ì¥ ì¶”ì¶œ
                sentences = re.split(r'[ã€‚.\n]', holding)
                if len(sentences) > 1:
                    # ì²« 3-5ë¬¸ì¥ì„ ìš”ì§€ë¡œ ì‚¬ìš©
                    holding_summary = '. '.join(sentences[:5]).strip()
                    if len(holding_summary) > 500:
                        holding_summary = holding_summary[:500] + "..."
                    logger.info(f"íŒë‹¨ ì„¹ì…˜ì—ì„œ íŒê²° ìš”ì§€ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(holding_summary)})")
                    return holding_summary
                elif len(holding) > 500:
                    holding = holding[:500] + "..."
                    logger.info(f"íŒë‹¨ ì„¹ì…˜ì—ì„œ íŒê²° ìš”ì§€ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(holding)})")
                    return holding
        
        logger.warning("íŒê²° ìš”ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    
    def extract_case_overview(self, text: str) -> str:
        """
        ì‚¬ê±´ ê°œìš”ë¥¼ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            ì •ë¦¬ëœ ì‚¬ê±´ ê°œìš” ë‚´ìš©
        """
        # ã€ì‚¬ê±´ ê°œìš”ã€‘ ë˜ëŠ” ã€ì „ë¬¸ã€‘ ì„¹ì…˜ ì°¾ê¸°
        overview_patterns = [
            r'ã€?\s*ì‚¬ê±´\s*ê°œìš”\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            r'ã€?\s*ì „ë¬¸\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
        ]
        
        for pattern in overview_patterns:
            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            if match:
                overview = match.group(1).strip()
                
                # í”¼ê³ ì¸, ìƒê³ ì¸, ë³€í˜¸ì¸, ì›ì‹¬íŒê²° ì •ë³´ ì¶”ì¶œ
                extracted_info = {}
                
                # ã€í”¼ê³ ì¸ã€‘, ã€ìƒê³ ì¸ã€‘, ã€ë³€í˜¸ì¸ã€‘, ã€ì›ì‹¬íŒê²°ã€‘ íŒ¨í„´ìœ¼ë¡œ ì¶”ì¶œ
                info_patterns = [
                    (r'ã€í”¼\s*ê³ \s*ì¸ã€‘\s*(.+?)(?=\nã€|$)', 'í”¼ê³ ì¸'),
                    (r'ã€ìƒ\s*ê³ \s*ì¸ã€‘\s*(.+?)(?=\nã€|$)', 'ìƒê³ ì¸'),
                    (r'ã€ë³€\s*í˜¸\s*ì¸ã€‘\s*(.+?)(?=\nã€|$)', 'ë³€í˜¸ì¸'),
                    (r'ã€ì›ì‹¬\s*íŒê²°ã€‘\s*(.+?)(?=\nã€|$)', 'ì›ì‹¬íŒê²°'),
                    (r'ã€ì£¼\s*ë¬¸ã€‘\s*(.+?)(?=\nã€|$)', 'ì£¼ë¬¸'),
                ]
                
                for pattern, label in info_patterns:
                    info_match = re.search(pattern, overview, re.DOTALL | re.IGNORECASE)
                    if info_match:
                        info_content = info_match.group(1).strip()
                        info_content = self.clean_section_content(info_content)
                        if info_content and len(info_content) > 3:  # ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œì™¸
                            extracted_info[label] = info_content
                
                # ì¶”ì¶œëœ ì •ë³´ë¥¼ êµ¬ì¡°í™”
                if extracted_info:
                    overview_parts = []
                    for label, content in extracted_info.items():
                        overview_parts.append(f"{label}: {content}")
                    result = "\n".join(overview_parts)
                    result = self.clean_section_content(result)
                    logger.info("ì‚¬ê±´ ê°œìš” ì¶”ì¶œ ì™„ë£Œ")
                    return result
                else:
                    # íŒ¨í„´ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ ì„¹ì…˜ ì •ì œ í›„ ë°˜í™˜
                    cleaned_overview = self.clean_section_content(overview)
                    if cleaned_overview and len(cleaned_overview) > 20:
                        logger.info("ì‚¬ê±´ ê°œìš” ì¶”ì¶œ ì™„ë£Œ (ì „ì²´ ì„¹ì…˜)")
                        return cleaned_overview
        
        logger.warning("ì‚¬ê±´ ê°œìš” ì„¹ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return ""
    
    def extract_judgment_section(self, text: str) -> str:
        """
        íŒë‹¨ ì„¹ì…˜ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
        í•˜ê¸‰ì‹¬ íŒë¡€ì˜ ê²½ìš° íŒë‹¨ ì„¹ì…˜ì´ ë§¤ìš° ê¸¸ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            ì •ë¦¬ëœ íŒë‹¨ ë‚´ìš©
        """
        # íŒë‹¨ ì„¹ì…˜ ì°¾ê¸° (ì—¬ëŸ¬ íŒ¨í„´ ì‹œë„, í•˜ê¸‰ì‹¬ íŒ¨í„´ í¬í•¨)
        judgment_patterns = [
            r'ã€?\s*íŒ\s*ë‹¨\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            r'ã€?\s*ì´\s*ìœ \s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            r'ã€?\s*ë‹¹ì‹¬\s*ì˜\s*íŒë‹¨\s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            r'ã€?\s*íŒ\s*ë‹¨\s*ë°\s*ì´\s*ìœ \s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',  # í•˜ê¸‰ì‹¬ íŒ¨í„´
            r'ã€?\s*ì´\s*ìœ \s*ã€‘?\s*[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',  # í•˜ê¸‰ì‹¬: ì´ìœ ë§Œ ìˆëŠ” ê²½ìš°
        ]
        
        for pattern in judgment_patterns:
            match = re.search(pattern, text, re.DOTALL | re.IGNORECASE)
            if match:
                judgment = match.group(1).strip()
                # ì •ì œ
                judgment = self.clean_section_content(judgment)
                if judgment and len(judgment) > 50:  # ìµœì†Œ ê¸¸ì´ í™•ì¸
                    # í•˜ê¸‰ì‹¬ íŒë¡€ëŠ” íŒë‹¨ì´ ë§¤ìš° ê¸¸ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìµœëŒ€ 5000ìê¹Œì§€ í—ˆìš©
                    if len(judgment) > 5000:
                        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ìë¥´ê¸°
                        sentences = re.split(r'[ã€‚.\n]', judgment)
                        judgment = '. '.join(sentences[:100])  # ìµœëŒ€ 100ë¬¸ì¥
                        if len(judgment) > 5000:
                            judgment = judgment[:5000] + "..."
                    logger.info(f"íŒë‹¨ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(judgment)})")
                    return judgment
        
        # íŒë‹¨ ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš°, "ã€íŒë‹¨ã€‘" ë˜ëŠ” "ã€ì´ìœ ã€‘" í‚¤ì›Œë“œ ì´í›„ì˜ í…ìŠ¤íŠ¸ ì‚¬ìš©
        # (í•˜ê¸‰ì‹¬ íŒë¡€ëŠ” ì„¹ì…˜ í—¤ë”ê°€ ì—†ì„ ìˆ˜ ìˆìŒ)
        judgment_keywords = ['íŒë‹¨', 'ì´ìœ ', 'ë‹¹ì‹¬ì˜ íŒë‹¨']
        for keyword in judgment_keywords:
            keyword_pos = text.find(keyword)
            if keyword_pos > 0:
                # í‚¤ì›Œë“œ ì´í›„ì˜ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìµœëŒ€ 5000ì)
                potential_judgment = text[keyword_pos + len(keyword):keyword_pos + 5000].strip()
                potential_judgment = self.clean_section_content(potential_judgment)
                if potential_judgment and len(potential_judgment) > 100:
                    logger.info(f"í‚¤ì›Œë“œ '{keyword}' ì´í›„ í…ìŠ¤íŠ¸ì—ì„œ íŒë‹¨ ì„¹ì…˜ ì¶”ì¶œ ì™„ë£Œ (ê¸¸ì´: {len(potential_judgment)})")
                    return potential_judgment
        
        return ""
    
    def extract_issue_section(self, text: str) -> str:
        """
        ìŸì  ì„¹ì…˜ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            ì •ë¦¬ëœ ìŸì  ë‚´ìš©
        """
        issue_match = re.search(
            r'ã€?\s*ìŸ\s*ì \s*ã€‘?[:\s]*\n?(.+?)(?=\n\n|\nã€|$)',
            text,
            re.DOTALL | re.IGNORECASE
        )
        if issue_match:
            issue = issue_match.group(1).strip()
            issue = self.clean_section_content(issue)
            if issue and len(issue) > 20:
                return issue
        return ""
    
    def extract_content(self, text: str, judgment_section: str = "") -> str:
        """
        íŒë¡€ ë‚´ìš©ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•©ë‹ˆë‹¤.
        í•˜ê¸‰ì‹¬ íŒë¡€ì˜ ê²½ìš° íŒë‹¨ ì„¹ì…˜ì´ ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            judgment_section: ì´ë¯¸ ì¶”ì¶œëœ íŒë‹¨ ì„¹ì…˜ (ì¤‘ë³µ ì¶”ì¶œ ë°©ì§€)
            
        Returns:
            ì •ë¦¬ëœ íŒë¡€ ë‚´ìš©
        """
        # ê° ì„¹ì…˜ì„ ê°œë³„ì ìœ¼ë¡œ ì¶”ì¶œ
        sections_dict = {}
        
        # 1. ì‚¬ê±´ ê°œìš” ì¶”ì¶œ
        overview = self.extract_case_overview(text)
        if overview:
            sections_dict["overview"] = overview
        
        # 2. ìŸì  ì¶”ì¶œ
        issue = self.extract_issue_section(text)
        if issue:
            sections_dict["issue"] = issue
        
        # 3. íŒë‹¨ ì¶”ì¶œ (ì´ë¯¸ ì¶”ì¶œëœ ê²½ìš° ì¬ì‚¬ìš©, ì—†ìœ¼ë©´ ìƒˆë¡œ ì¶”ì¶œ)
        if judgment_section:
            judgment = judgment_section
        else:
            judgment = self.extract_judgment_section(text)
        if judgment:
            sections_dict["judgment"] = judgment
        
        # 4. íŒê²° ìš”ì§€ ì¶”ì¶œ (íŒë‹¨ ì„¹ì…˜ì„ ì‚¬ìš©í•˜ì—¬ ìš”ì§€ ìƒì„±)
        holding = self.extract_holding(text, judgment if judgment else "")
        if holding:
            sections_dict["holding"] = holding
        
        # ì„¹ì…˜ë“¤ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬
        if sections_dict:
            formatted_content = self.format_content_sections(sections_dict)
            if formatted_content:
                return formatted_content
        
        # ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš© (ì²˜ìŒ 5000ì)
        content = text[:5000].strip()
        content = self.clean_section_content(content)
        logger.warning("ì£¼ìš” ì„¹ì…˜ì„ ì°¾ì§€ ëª»í•´ ì „ì²´ í…ìŠ¤íŠ¸ ì¼ë¶€ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return content
    
    def clean_content(self, content: str) -> str:
        """ë‚´ìš© ì •ì œ"""
        # ë¶ˆí•„ìš”í•œ ê³µë°± ì œê±°
        content = re.sub(r'\s+', ' ', content)
        # ì¤„ë°”ê¿ˆ ì •ë¦¬
        content = re.sub(r'\n\s*\n+', '\n\n', content)
        # ì•ë’¤ ê³µë°± ì œê±°
        content = content.strip()
        return content
    
    def format_content_sections(self, sections: Dict[str, str]) -> str:
        """
        ì¶”ì¶œëœ ì„¹ì…˜ë“¤ì„ êµ¬ì¡°í™”ëœ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•©ë‹ˆë‹¤.
        
        Args:
            sections: ì„¹ì…˜ë³„ ë‚´ìš© ë”•ì…”ë„ˆë¦¬
                {
                    "overview": "...",
                    "issue": "...",
                    "judgment": "...",
                    "holding": "..."
                }
        
        Returns:
            ì •ë¦¬ëœ content ë¬¸ìì—´
        """
        formatted_parts = []
        
        # 1. ì‚¬ê±´ ê°œìš”
        if sections.get("overview"):
            overview = self.clean_section_content(sections["overview"])
            if overview:
                formatted_parts.append(f"ã€ì‚¬ê±´ ê°œìš”ã€‘\n{overview}")
        
        # 2. ìŸì 
        if sections.get("issue"):
            issue = self.clean_section_content(sections["issue"])
            if issue:
                formatted_parts.append(f"ã€ìŸì ã€‘\n{issue}")
        
        # 3. íŒë‹¨
        if sections.get("judgment"):
            judgment = self.clean_section_content(sections["judgment"])
            if judgment:
                formatted_parts.append(f"ã€íŒë‹¨ã€‘\n{judgment}")
        
        # 4. íŒê²° ìš”ì§€
        if sections.get("holding"):
            holding = self.clean_section_content(sections["holding"])
            if holding:
                formatted_parts.append(f"ã€íŒê²° ìš”ì§€ã€‘\n{holding}")
        
        if formatted_parts:
            return "\n\n".join(formatted_parts)
        
        return ""
    
    def clean_section_content(self, content: str) -> str:
        """
        ì„¹ì…˜ ë‚´ìš©ì„ ì •ì œí•©ë‹ˆë‹¤.
        
        Args:
            content: ì›ë³¸ ì„¹ì…˜ ë‚´ìš©
            
        Returns:
            ì •ì œëœ ë‚´ìš©
        """
        if not content:
            return ""
        
        # 1. ë¶ˆí•„ìš”í•œ í—¤ë”/í‘¸í„° ì œê±°
        # ë²•ì œì²˜, êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„° ë“± ì œê±°
        content = re.sub(r'ë²•ì œì²˜\s*\d+\s*êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°[^\n]*', '', content)
        content = re.sub(r'êµ­ê°€ë²•ë ¹ì •ë³´ì„¼í„°[^\n]*', '', content)
        content = re.sub(r'\"[^\"]*\"\s*\(íŒë¡€[^)]*\)', '', content)
        content = re.sub(r'\(íŒë¡€[^)]*\)', '', content)
        
        # 2. ì„¹ì…˜ í—¤ë” ì¤‘ë³µ ì œê±°
        content = re.sub(r'^ã€?\s*ì‚¬ê±´\s*ê°œìš”\s*ã€‘?[:\s]*\n?', '', content, flags=re.IGNORECASE | re.MULTILINE)
        content = re.sub(r'^ã€?\s*ìŸ\s*ì \s*ã€‘?[:\s]*\n?', '', content, flags=re.IGNORECASE | re.MULTILINE)
        content = re.sub(r'^ã€?\s*íŒ\s*ë‹¨\s*ã€‘?[:\s]*\n?', '', content, flags=re.IGNORECASE | re.MULTILINE)
        content = re.sub(r'^ã€?\s*íŒê²°\s*ìš”ì§€\s*ã€‘?[:\s]*\n?', '', content, flags=re.IGNORECASE | re.MULTILINE)
        
        # 3. ë¶ˆì™„ì „í•œ ì„¹ì…˜ ì œê±°
        # "ã€í”¼ ê³  ì¸ã€‘" ê°™ì€ ë¶ˆì™„ì „í•œ ì„¹ì…˜ë§Œ ìˆëŠ” ê²½ìš° ì œê±°
        content = re.sub(r'^ã€[^ã€‘]+ã€‘\s*$', '', content, flags=re.MULTILINE)
        # "ã€í”¼ ê³  ì¸ã€‘ í”¼ê³ ì¸" ê°™ì€ ë‹¨ìˆœ ë°˜ë³µ ì œê±°
        content = re.sub(r'ã€í”¼\s*ê³ \s*ì¸ã€‘\s*í”¼ê³ ì¸\s*', '', content, flags=re.IGNORECASE)
        
        # 4. ë¬¸ì¥ ë¶€í˜¸ ì •ë¦¬
        # ì—°ì†ëœ ë§ˆì¹¨í‘œ ì œê±° (.. -> .)
        content = re.sub(r'\.{2,}', '.', content)
        # ë§ˆì¹¨í‘œ ì• ê³µë°± ì œê±° (ë‹¨, ìˆ«ì ë’¤ëŠ” ì œì™¸)
        content = re.sub(r'([^0-9])\s+\.', r'\1.', content)
        # ë§ˆì¹¨í‘œ ë’¤ ê³µë°± ì •ë¦¬ (í•œ ì¹¸ë§Œ, ì¤„ë°”ê¿ˆ ì œì™¸)
        content = re.sub(r'\.\s+([^\n])', r'. \1', content)
        # ì—°ì†ëœ ê³µë°±ì„ í•˜ë‚˜ë¡œ
        content = re.sub(r' {2,}', ' ', content)
        
        # 5. ë‚ ì§œ í˜•ì‹ ì •ë¦¬
        # "2008. 9. 8. ê²½" -> "2008. 9. 8.ê²½"
        content = re.sub(r'(\d{4})\.\s*(\d{1,2})\.\s*(\d{1,2})\.\s+ê²½', r'\1. \2. \3.ê²½', content)
        # "2008. 9. 8." -> "2008. 9. 8."
        content = re.sub(r'(\d{4})\.\s+(\d{1,2})\.\s+(\d{1,2})\.', r'\1. \2. \3.', content)
        # "2011. 1. ê²½" -> "2011. 1.ê²½"
        content = re.sub(r'(\d{4})\.\s*(\d{1,2})\.\s+ê²½', r'\1. \2.ê²½', content)
        
        # 6. í•­ëª© í‘œì‹œ ì •ë¦¬ (ê°€., ë‚˜., ë‹¤. ë“±)
        # "ê°€ í”¼í•´ì" -> "ê°€. í”¼í•´ì"
        content = re.sub(r'\b([ê°€-í£])\s+([ê°€-í£])', r'\1. \2', content)
        # ë‹¨, ì´ë¯¸ ë§ˆì¹¨í‘œê°€ ìˆëŠ” ê²½ìš°ëŠ” ì œì™¸
        content = re.sub(r'([ê°€-í£])\.\s*\.', r'\1.', content)
        
        # 6. ë¶ˆí•„ìš”í•œ ê³µë°± ì •ë¦¬
        content = re.sub(r'[ \t]+', ' ', content)  # íƒ­ê³¼ ê³µë°±ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ
        content = re.sub(r'\n[ \t]+', '\n', content)  # ì¤„ ì‹œì‘ ê³µë°± ì œê±°
        content = re.sub(r'[ \t]+\n', '\n', content)  # ì¤„ ë ê³µë°± ì œê±°
        content = re.sub(r'\n{3,}', '\n\n', content)  # 3ê°œ ì´ìƒ ì¤„ë°”ê¿ˆì„ 2ê°œë¡œ
        
        # 7. ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ íŒ¨í„´ ì œê±°
        # "ë²•ì œì²˜ 3" ê°™ì€ íŒ¨í„´
        content = re.sub(r'ë²•ì œì²˜\s*\d+', '', content)
        # í˜ì´ì§€ ë²ˆí˜¸ ê°™ì€ íŒ¨í„´
        content = re.sub(r'\n\s*\d+\s*\n', '\n', content)
        
        # 8. ë¬¸ì¥ì´ ì´ìƒí•˜ê²Œ ëŠì–´ì§„ ê²½ìš° ìˆ˜ì •
        # "ì‚¬ì‹¤ì„. ì˜¤ì¸í•˜ê±°ë‚˜" -> "ì‚¬ì‹¤ì„ ì˜¤ì¸í•˜ê±°ë‚˜"
        content = re.sub(r'([ê°€-í£])\s*\.\s*([ê°€-í£])', r'\1 \2', content)
        
        # 9. ì•ë’¤ ê³µë°± ì œê±°
        content = content.strip()
        
        # 10. ë„ˆë¬´ ì§§ì€ ë‚´ìš© ì œê±° (10ì ë¯¸ë§Œ)
        if len(content) < 10:
            return ""
        
        return content
    
    def extract_keywords(self, text: str, sub_category: str = "") -> list[str]:
        """
        í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            sub_category: í•˜ìœ„ ì¹´í…Œê³ ë¦¬
            
        Returns:
            í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
        """
        keywords = []
        
        # í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ í‚¤ì›Œë“œì— ì¶”ê°€
        if sub_category:
            keywords.append(sub_category)
        
        # ì¼ë°˜ì ì¸ ë²•ë¥  í‚¤ì›Œë“œ
        common_keywords = [
            "ì‚¬ê¸°", "ì ˆë„", "ê°•ë„", "ì‚´ì¸", "í­í–‰", "í˜‘ë°•",
            "ì´ˆë²”", "ì¬ë²”", "ì§‘í–‰ìœ ì˜ˆ", "ì‹¤í˜•", "ë²Œê¸ˆ",
            "í”¼í•´íšŒë³µ", "ë°˜ì„±", "ì–‘í˜•", "ê°€ì¤‘ì²˜ë²Œ",
        ]
        
        for keyword in common_keywords:
            if keyword in text and keyword not in keywords:
                keywords.append(keyword)
        
        return keywords[:5]  # ìµœëŒ€ 5ê°œ
    
    def determine_category(self, text: str) -> tuple[str, str]:
        """
        ì¹´í…Œê³ ë¦¬ì™€ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë¥¼ ê²°ì •í•©ë‹ˆë‹¤.
        
        Args:
            text: PDF í…ìŠ¤íŠ¸
            
        Returns:
            (category, sub_category) íŠœí”Œ
        """
        # í˜•ì‚¬ ê´€ë ¨ í‚¤ì›Œë“œ
        criminal_keywords = {
            "ì‚¬ê¸°": ["ì‚¬ê¸°", "í¸ì·¨", "ê¸°ë§"],
            "ì ˆë„": ["ì ˆë„", "ì ˆì·¨"],
            "ê°•ë„": ["ê°•ë„", "ê°•ì·¨"],
            "ì‚´ì¸": ["ì‚´ì¸", "ê³ ì˜"],
            "í­í–‰": ["í­í–‰", "ìƒí•´"],
            "ì´ˆë²”": ["ì´ˆë²”", "ì „ê³¼"],
            "ì§‘í–‰ìœ ì˜ˆ": ["ì§‘í–‰ìœ ì˜ˆ", "ìœ ì˜ˆ"],
        }
        
        # ë¯¼ì‚¬ ê´€ë ¨ í‚¤ì›Œë“œ
        civil_keywords = {
            "ê³„ì•½": ["ê³„ì•½", "í•´ì œ", "í•´ì§€"],
            "ì†í•´ë°°ìƒ": ["ì†í•´ë°°ìƒ", "ë°°ìƒ"],
            "ì„ëŒ€ì°¨": ["ì„ëŒ€ì°¨", "ì„ì°¨"],
        }
        
        # í˜•ì‚¬ íŒë¡€ì¸ì§€ í™•ì¸
        for sub_cat, keywords in criminal_keywords.items():
            if any(kw in text[:2000] for kw in keywords):
                return ("í˜•ì‚¬", sub_cat)
        
        # ë¯¼ì‚¬ íŒë¡€ì¸ì§€ í™•ì¸
        for sub_cat, keywords in civil_keywords.items():
            if any(kw in text[:2000] for kw in keywords):
                return ("ë¯¼ì‚¬", sub_cat)
        
        # ê¸°ë³¸ê°’
        return ("í˜•ì‚¬", "")
    
    def create_case_json(
        self,
        court: str,
        case_number: Optional[str],
        year: int,
        content: str,
        holding: str,
        category: str,
        sub_category: str,
        keywords: list[str],
        judgment_date: Optional[str] = None,
        panji_items: Optional[List[str]] = None,
        reference_articles: Optional[List[str]] = None,
        reference_cases: Optional[List[str]] = None,
    ) -> Dict[str, Any]:
        """
        íŒë¡€ ë°ì´í„°ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            court: ë²•ì›ëª…
            case_number: ì‚¬ê±´ë²ˆí˜¸
            year: íŒê²° ì—°ë„
            content: íŒë¡€ ë‚´ìš©
            holding: íŒê²° ìš”ì§€
            category: ì¹´í…Œê³ ë¦¬
            sub_category: í•˜ìœ„ ì¹´í…Œê³ ë¦¬
            keywords: í‚¤ì›Œë“œ ë¦¬ìŠ¤íŠ¸
            judgment_date: íŒê²°ì¼ (YYYY-MM-DD)
            panji_items: íŒì‹œì‚¬í•­ ë¦¬ìŠ¤íŠ¸
            reference_articles: ì°¸ì¡°ì¡°ë¬¸ ë¦¬ìŠ¤íŠ¸
            reference_cases: ì°¸ì¡°íŒë¡€ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            JSON í˜•ì‹ì˜ íŒë¡€ ë°ì´í„°
        """
        # ID ìƒì„±
        if case_number:
            doc_id = f"case-{case_number}"
        else:
            doc_id = f"case-{court}-{year}-{sub_category or 'unknown'}"
        
        # ì œëª© ìƒì„±
        if case_number:
            title = f"{court} {case_number} íŒê²°"
        else:
            title = f"{court} {year}ë…„ {sub_category or ''} íŒê²°"
        
        # ë©”íƒ€ë°ì´í„° êµ¬ì„±
        metadata = {
            "court": court,
            "year": year,
            "case_number": case_number or "",
            "keywords": keywords,
            "holding": holding,
            "updated_at": datetime.now().strftime("%Y-%m-%d"),
        }
        
        # íŒê²°ì¼ ì¶”ê°€
        if judgment_date:
            metadata["judgment_date"] = judgment_date
        
        # íŒì‹œì‚¬í•­ ì¶”ê°€
        if panji_items:
            metadata["panji_items"] = panji_items
        
        # ì°¸ì¡°ì¡°ë¬¸ ì¶”ê°€
        if reference_articles:
            metadata["reference_articles"] = reference_articles
        
        # ì°¸ì¡°íŒë¡€ ì¶”ê°€
        if reference_cases:
            metadata["reference_cases"] = reference_cases
        
        return {
            "id": doc_id,
            "category": category,
            "sub_category": sub_category,
            "type": "case",
            "title": title,
            "content": content,
            "metadata": metadata,
        }
    
    def save_case(self, case_data: Dict[str, Any]) -> Path:
        """
        íŒë¡€ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            case_data: íŒë¡€ ë°ì´í„°
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        # íŒŒì¼ëª…: "case-2023ë„11234.json"
        filename = f"{case_data['id']}.json"
        file_path = self.output_dir / filename
        
        # JSON íŒŒì¼ ì €ì¥
        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(case_data, f, ensure_ascii=False, indent=2)
        
        return file_path
    
    def parse_and_save(self, pdf_path: Path) -> Optional[Path]:
        """
        PDFë¥¼ íŒŒì‹±í•˜ì—¬ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            
        Returns:
            ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
        """
        logger.info(f"íŒë¡€ PDF íŒŒì‹± ì‹œì‘: {pdf_path}")
        
        # PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = self.parse_pdf_text(pdf_path)
        
        # ì •ë³´ ì¶”ì¶œ
        case_number = self.extract_case_number(text, pdf_path)
        court = self.extract_court(text, case_number)
        judgment_date = self.extract_judgment_date(text)
        year = self.extract_year(text, case_number, judgment_date)  # íŒê²°ì¼ ìš°ì„  ì‚¬ìš©
        judgment_section = self.extract_judgment_section(text)  # íŒë‹¨ ì„¹ì…˜ ë¨¼ì € ì¶”ì¶œ
        holding = self.extract_holding(text, judgment_section)  # íŒë‹¨ ì„¹ì…˜ì„ ìš”ì§€ ì¶”ì¶œì— ì‚¬ìš©
        content = self.extract_content(text, judgment_section)  # íŒë‹¨ ì„¹ì…˜ì„ content ì¶”ì¶œì— ì‚¬ìš©
        category, sub_category = self.determine_category(text)
        keywords = self.extract_keywords(text, sub_category)
        panji_items = self.extract_panji_items(text)
        reference_articles = self.extract_reference_articles(text)
        reference_cases = self.extract_reference_cases(text)
        
        logger.info(f"ì¶”ì¶œëœ ì •ë³´:")
        logger.info(f"  - ë²•ì›: {court}")
        logger.info(f"  - ì‚¬ê±´ë²ˆí˜¸: {case_number or 'ì—†ìŒ'}")
        logger.info(f"  - ì—°ë„: {year}")
        logger.info(f"  - íŒê²°ì¼: {judgment_date or 'ì—†ìŒ'}")
        logger.info(f"  - ì¹´í…Œê³ ë¦¬: {category} > {sub_category}")
        logger.info(f"  - íŒì‹œì‚¬í•­: {len(panji_items)}ê°œ")
        logger.info(f"  - ì°¸ì¡°ì¡°ë¬¸: {len(reference_articles)}ê°œ")
        logger.info(f"  - ì°¸ì¡°íŒë¡€: {len(reference_cases)}ê°œ")
        
        # JSON ë°ì´í„° ìƒì„±
        case_data = self.create_case_json(
            court=court,
            case_number=case_number,
            year=year,
            content=content,
            holding=holding,
            category=category,
            sub_category=sub_category,
            keywords=keywords,
            judgment_date=judgment_date,
            panji_items=panji_items if panji_items else None,
            reference_articles=reference_articles if reference_articles else None,
            reference_cases=reference_cases if reference_cases else None,
        )
        
        # íŒŒì¼ ì €ì¥
        file_path = self.save_case(case_data)
        logger.info(f"ì €ì¥ ì™„ë£Œ: {file_path}")
        
        return file_path


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    import argparse
    
    parser = argparse.ArgumentParser(description="íŒë¡€ PDFë¥¼ JSONìœ¼ë¡œ ë³€í™˜")
    parser.add_argument(
        "path",
        type=Path,
        help="PDF íŒŒì¼ ê²½ë¡œ ë˜ëŠ” í´ë” ê²½ë¡œ"
    )
    parser.add_argument(
        "--output-dir",
        type=Path,
        default=Path("data/collected/cases"),
        help="ì¶œë ¥ ë””ë ‰í† ë¦¬ (ê¸°ë³¸ê°’: data/collected/cases)"
    )
    parser.add_argument(
        "--f",
        "--folder",
        dest="folder_mode",
        action="store_true",
        help="í´ë” ëª¨ë“œ: ì§€ì •ëœ í´ë”ì˜ ëª¨ë“  PDF íŒŒì¼ì„ ì²˜ë¦¬"
    )
    
    args = parser.parse_args()
    
    if not args.path.exists():
        logger.error(f"ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.path}")
        return
    
    parser_obj = CasePDFParser(args.output_dir)
    
    # í´ë” ëª¨ë“œì¸ì§€ í™•ì¸
    if args.folder_mode or args.path.is_dir():
        # í´ë” ëª¨ë“œ: ëª¨ë“  PDF íŒŒì¼ ì°¾ê¸°
        pdf_files = list(args.path.glob("*.pdf"))
        
        if not pdf_files:
            logger.warning(f"í´ë”ì— PDF íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {args.path}")
            return
        
        logger.info(f"ì´ {len(pdf_files)}ê°œì˜ PDF íŒŒì¼ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        print(f"\nğŸ“ í´ë” ëª¨ë“œ: {len(pdf_files)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘\n")
        
        success_count = 0
        error_count = 0
        error_files = []
        
        for idx, pdf_file in enumerate(pdf_files, 1):
            print(f"[{idx}/{len(pdf_files)}] ì²˜ë¦¬ ì¤‘: {pdf_file.name}")
            try:
                saved_file = parser_obj.parse_and_save(pdf_file)
                success_count += 1
                print(f"  âœ… ì™„ë£Œ: {saved_file.name}\n")
            except Exception as e:
                error_count += 1
                error_files.append(pdf_file.name)
                logger.error(f"  âŒ ì˜¤ë¥˜ ë°œìƒ ({pdf_file.name}): {str(e)}")
                print(f"  âŒ ì˜¤ë¥˜: {str(e)}\n")
        
        # ê²°ê³¼ ìš”ì•½
        print("\n" + "="*60)
        print(f"ğŸ“Š ì²˜ë¦¬ ì™„ë£Œ ìš”ì•½")
        print("="*60)
        print(f"âœ… ì„±ê³µ: {success_count}ê°œ")
        print(f"âŒ ì‹¤íŒ¨: {error_count}ê°œ")
        print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output_dir}")
        
        if error_files:
            print(f"\nâš ï¸  ì‹¤íŒ¨í•œ íŒŒì¼:")
            for file in error_files:
                print(f"  - {file}")
        print("="*60)
        
    else:
        # ë‹¨ì¼ íŒŒì¼ ëª¨ë“œ
        if not args.path.is_file():
            logger.error(f"PDF íŒŒì¼ì´ ì•„ë‹™ë‹ˆë‹¤: {args.path}")
            return
        
        saved_file = parser_obj.parse_and_save(args.path)
        
        if saved_file:
            print(f"\nâœ… ë³€í™˜ ì™„ë£Œ!")
            print(f"ğŸ“ ì €ì¥ ìœ„ì¹˜: {args.output_dir}")
            print(f"ğŸ“„ ìƒì„±ëœ íŒŒì¼: {saved_file}")
        else:
            print("\nâŒ ë³€í™˜ ì‹¤íŒ¨")


if __name__ == "__main__":
    main()

